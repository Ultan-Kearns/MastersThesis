{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxJ2XxxZeozF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742e33fa-4b7f-41ce-c12a-f1545af06a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            " COVID\t\t\t      Normal.metadata.xlsx\n",
            " COVID.metadata.xlsx\t      README.md.txt\n",
            " Lung_Opacity.metadata.xlsx  'Viral Pneumonia'\n",
            " Normal\t\t\t     'Viral Pneumonia.metadata.xlsx'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
            "Collecting install\n",
            "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (23.0)\n",
            "Installing collected packages: tensorflow-addons, install\n",
            "Successfully installed install-1.3.5 tensorflow-addons-0.19.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls \"/content/gdrive/My Drive/COVID-19_Radiography_Dataset\"\n",
        "!pip install pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from IPython import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from enum import Enum\n",
        "from glob import glob\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import gdown\n",
        "from zipfile import ZipFile\n",
        "# for reproducibility - ref https://machinelearningmastery.com/reproducible-results-neural-networks-keras/ and https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed\n",
        "np.random.seed(9)\n",
        "tf.keras.utils.set_random_seed(10)\n",
        "\n",
        "# loading data from gdrive\n",
        "chest_xray_dataset = os.path.abspath(\"/content/gdrive/My Drive/COVID 19 CHEST XRAY/images\")\n",
        "chest_xray_dataset_annotations = os.path.abspath(\"/content/gdrive/My Drive/COVID 19 CHEST XRAY/metadata.csv\")\n",
        "radiography_dataset = os.path.abspath(\"/content/gdrive/My Drive/COVID-19_Radiography_Dataset/\")\n",
        "xray_covid19_dataset = os.path.abspath(\"/content/gdrive/My Drive/xray_dataset_covid19/\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zES2UFFZe1wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #**Anti-Disconnect for Google Colab**\n",
        "#@markdown ## Run this to stop it from disconnecting automatically \n",
        "#@markdown  **(It will anyhow disconnect after 6 - 12 hrs for using the free version of Colab.)**\n",
        "#@markdown  *(Colab Pro users will get about 24 hrs usage time)*\n",
        "#@markdown ---\n",
        "# taken from https://colab.research.google.com/github/justinjohn0306/VQGAN-CLIP/blob/main/VQGAN%2BCLIP_%28z%2Bquantize_method_with_augmentations%2C_user_friendly_interface%29.ipynb#scrollTo=XHyPd4oxVp_l stops colab disconnecting\n",
        "import IPython\n",
        "js_code = '''\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''\n",
        "IPython.display.Javascript(js_code)"
      ],
      "metadata": {
        "id": "E-YIPb97e2-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "baf0bfc5-7f29-480a-9a34-8d4bbbaa7011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}\n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imageDf = pd.read_csv(chest_xray_dataset_annotations)\n",
        "print(imageDf)\n"
      ],
      "metadata": {
        "id": "IdBVJ9o7e4vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53932cae-6194-4309-8a19-f2f0ef862455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     patientid  offset sex   age   finding survival intubated  \\\n",
            "0            2     0.0   M  65.0  COVID-19        Y       NaN   \n",
            "1            2     3.0   M  65.0  COVID-19        Y       NaN   \n",
            "2            2     5.0   M  65.0  COVID-19        Y       NaN   \n",
            "3            2     6.0   M  65.0  COVID-19        Y       NaN   \n",
            "4            4     0.0   F  52.0  COVID-19      NaN       NaN   \n",
            "..         ...     ...  ..   ...       ...      ...       ...   \n",
            "367        205    11.0   M  55.0  COVID-19        Y       NaN   \n",
            "368        205    13.0   M  55.0  COVID-19        Y       NaN   \n",
            "369        205    20.0   M  55.0  COVID-19        Y       NaN   \n",
            "370        205    24.0   M  55.0  COVID-19        Y       NaN   \n",
            "371        205    28.0   M  55.0  COVID-19        Y       NaN   \n",
            "\n",
            "    intubation_present went_icu in_icu  ...              date  \\\n",
            "0                  NaN      NaN    NaN  ...  January 22, 2020   \n",
            "1                  NaN      NaN    NaN  ...  January 25, 2020   \n",
            "2                  NaN      NaN    NaN  ...  January 27, 2020   \n",
            "3                  NaN      NaN    NaN  ...  January 28, 2020   \n",
            "4                  NaN      NaN    NaN  ...  January 25, 2020   \n",
            "..                 ...      ...    ...  ...               ...   \n",
            "367                  Y        Y      Y  ...               NaN   \n",
            "368                  Y        Y      Y  ...               NaN   \n",
            "369                  Y        Y      Y  ...               NaN   \n",
            "370                  N        Y      Y  ...               NaN   \n",
            "371                  N        Y      N  ...               NaN   \n",
            "\n",
            "                                              location  folder  \\\n",
            "0          Cho Ray Hospital, Ho Chi Minh City, Vietnam  images   \n",
            "1          Cho Ray Hospital, Ho Chi Minh City, Vietnam  images   \n",
            "2          Cho Ray Hospital, Ho Chi Minh City, Vietnam  images   \n",
            "3          Cho Ray Hospital, Ho Chi Minh City, Vietnam  images   \n",
            "4    Changhua Christian Hospital, Changhua City, Ta...  images   \n",
            "..                                                 ...     ...   \n",
            "367                               North Derbyshire, UK  images   \n",
            "368                               North Derbyshire, UK  images   \n",
            "369                               North Derbyshire, UK  images   \n",
            "370                               North Derbyshire, UK  images   \n",
            "371                               North Derbyshire, UK  images   \n",
            "\n",
            "                                              filename                   doi  \\\n",
            "0    auntminnie-a-2020_01_28_23_51_6665_2020_01_28_...  10.1056/nejmc2001272   \n",
            "1    auntminnie-b-2020_01_28_23_51_6665_2020_01_28_...  10.1056/nejmc2001272   \n",
            "2    auntminnie-c-2020_01_28_23_51_6665_2020_01_28_...  10.1056/nejmc2001272   \n",
            "3    auntminnie-d-2020_01_28_23_51_6665_2020_01_28_...  10.1056/nejmc2001272   \n",
            "4                                nejmc2001573_f1a.jpeg  10.1056/NEJMc2001573   \n",
            "..                                                 ...                   ...   \n",
            "367  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "368  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "369  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "370  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "371  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "\n",
            "                                                   url      license  \\\n",
            "0    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "1    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "2    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "3    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "4    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "..                                                 ...          ...   \n",
            "367  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "368  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "369  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "370  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "371  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "\n",
            "                                        clinical_notes  \\\n",
            "0    On January 22, 2020, a 65-year-old man with a ...   \n",
            "1    On January 22, 2020, a 65-year-old man with a ...   \n",
            "2    On January 22, 2020, a 65-year-old man with a ...   \n",
            "3    On January 22, 2020, a 65-year-old man with a ...   \n",
            "4     diffuse infiltrates in the bilateral lower lungs   \n",
            "..                                                 ...   \n",
            "367  ITU admission, Endotracheal tube, nasogastric ...   \n",
            "368  Lines and tubes suitably sited.  Minor regress...   \n",
            "369  increasing oxygen requirements. Extubated.  Po...   \n",
            "370  Extubated since the prior radiograph.  Partial...   \n",
            "371  Remarkable improvement in appearances since th...   \n",
            "\n",
            "                                           other_notes Unnamed: 28  \n",
            "0                                                  NaN         NaN  \n",
            "1                                                  NaN         NaN  \n",
            "2                                                  NaN         NaN  \n",
            "3                                                  NaN         NaN  \n",
            "4                                                  NaN         NaN  \n",
            "..                                                 ...         ...  \n",
            "367  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "368  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "369  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "370  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "371  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "\n",
            "[372 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (256, 256)\n",
        "batch_size = 16\n",
        "covid = imageDf.loc[(imageDf['finding'] == 'COVID-19')]\n",
        "datagen=ImageDataGenerator(rescale=1./255)\n",
        "train_generator=datagen.flow_from_dataframe(dataframe=imageDf, directory=chest_xray_dataset, x_col=\"filename\", y_col=\"finding\",class_mode='categorical',target_size=image_size, batch_size=16,crop_to_aspect_ratio=True)\n",
        "print(covid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-WJT7c9Zw39",
        "outputId": "084e6f44-e149-4f6f-adbf-736d0fad6bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 351 validated image filenames belonging to 11 classes.\n",
            "     patientid  offset sex   age   finding survival intubated  \\\n",
            "0            2     0.0   M  65.0  COVID-19        Y       NaN   \n",
            "1            2     3.0   M  65.0  COVID-19        Y       NaN   \n",
            "2            2     5.0   M  65.0  COVID-19        Y       NaN   \n",
            "3            2     6.0   M  65.0  COVID-19        Y       NaN   \n",
            "4            4     0.0   F  52.0  COVID-19      NaN       NaN   \n",
            "..         ...     ...  ..   ...       ...      ...       ...   \n",
            "367        205    11.0   M  55.0  COVID-19        Y       NaN   \n",
            "368        205    13.0   M  55.0  COVID-19        Y       NaN   \n",
            "369        205    20.0   M  55.0  COVID-19        Y       NaN   \n",
            "370        205    24.0   M  55.0  COVID-19        Y       NaN   \n",
            "371        205    28.0   M  55.0  COVID-19        Y       NaN   \n",
            "\n",
            "    intubation_present went_icu in_icu  ...              date  \\\n",
            "0                  NaN      NaN    NaN  ...  January 22, 2020   \n",
            "1                  NaN      NaN    NaN  ...  January 25, 2020   \n",
            "2                  NaN      NaN    NaN  ...  January 27, 2020   \n",
            "3                  NaN      NaN    NaN  ...  January 28, 2020   \n",
            "4                  NaN      NaN    NaN  ...  January 25, 2020   \n",
            "..                 ...      ...    ...  ...               ...   \n",
            "367                  Y        Y      Y  ...               NaN   \n",
            "368                  Y        Y      Y  ...               NaN   \n",
            "369                  Y        Y      Y  ...               NaN   \n",
            "370                  N        Y      Y  ...               NaN   \n",
            "371                  N        Y      N  ...               NaN   \n",
            "\n",
            "                                              location  folder  \\\n",
            "0          Cho Ray Hospital, Ho Chi Minh City, Vietnam  images   \n",
            "1          Cho Ray Hospital, Ho Chi Minh City, Vietnam  images   \n",
            "2          Cho Ray Hospital, Ho Chi Minh City, Vietnam  images   \n",
            "3          Cho Ray Hospital, Ho Chi Minh City, Vietnam  images   \n",
            "4    Changhua Christian Hospital, Changhua City, Ta...  images   \n",
            "..                                                 ...     ...   \n",
            "367                               North Derbyshire, UK  images   \n",
            "368                               North Derbyshire, UK  images   \n",
            "369                               North Derbyshire, UK  images   \n",
            "370                               North Derbyshire, UK  images   \n",
            "371                               North Derbyshire, UK  images   \n",
            "\n",
            "                                              filename                   doi  \\\n",
            "0    auntminnie-a-2020_01_28_23_51_6665_2020_01_28_...  10.1056/nejmc2001272   \n",
            "1    auntminnie-b-2020_01_28_23_51_6665_2020_01_28_...  10.1056/nejmc2001272   \n",
            "2    auntminnie-c-2020_01_28_23_51_6665_2020_01_28_...  10.1056/nejmc2001272   \n",
            "3    auntminnie-d-2020_01_28_23_51_6665_2020_01_28_...  10.1056/nejmc2001272   \n",
            "4                                nejmc2001573_f1a.jpeg  10.1056/NEJMc2001573   \n",
            "..                                                 ...                   ...   \n",
            "367  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "368  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "369  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "370  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "371  covid-19-pneumonia-progression-and-regression-...                   NaN   \n",
            "\n",
            "                                                   url      license  \\\n",
            "0    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "1    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "2    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "3    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "4    https://www.nejm.org/doi/full/10.1056/NEJMc200...          NaN   \n",
            "..                                                 ...          ...   \n",
            "367  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "368  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "369  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "370  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "371  https://radiopaedia.org/cases/covid-19-pneumon...  CC BY-NC-SA   \n",
            "\n",
            "                                        clinical_notes  \\\n",
            "0    On January 22, 2020, a 65-year-old man with a ...   \n",
            "1    On January 22, 2020, a 65-year-old man with a ...   \n",
            "2    On January 22, 2020, a 65-year-old man with a ...   \n",
            "3    On January 22, 2020, a 65-year-old man with a ...   \n",
            "4     diffuse infiltrates in the bilateral lower lungs   \n",
            "..                                                 ...   \n",
            "367  ITU admission, Endotracheal tube, nasogastric ...   \n",
            "368  Lines and tubes suitably sited.  Minor regress...   \n",
            "369  increasing oxygen requirements. Extubated.  Po...   \n",
            "370  Extubated since the prior radiograph.  Partial...   \n",
            "371  Remarkable improvement in appearances since th...   \n",
            "\n",
            "                                           other_notes Unnamed: 28  \n",
            "0                                                  NaN         NaN  \n",
            "1                                                  NaN         NaN  \n",
            "2                                                  NaN         NaN  \n",
            "3                                                  NaN         NaN  \n",
            "4                                                  NaN         NaN  \n",
            "..                                                 ...         ...  \n",
            "367  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "368  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "369  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "370  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "371  Case courtesy of Dr Ian Bickle, Radiopaedia.or...         NaN  \n",
            "\n",
            "[296 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 128"
      ],
      "metadata": {
        "id": "Enbth_0xaH6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(256, 256, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(2 * 2 * 128),\n",
        "        layers.Reshape((2, 2, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "             layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "             layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(3, kernel_size=3, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GW0C5Jfdd9f",
        "outputId": "38115d7c-0995-4d22-ae17-0b9c516388ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_47 (Conv2D)          (None, 128, 128, 64)      3136      \n",
            "                                                                 \n",
            " re_lu_113 (ReLU)            (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 64, 64, 128)       131200    \n",
            "                                                                 \n",
            " re_lu_114 (ReLU)            (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 32, 32, 128)       262272    \n",
            "                                                                 \n",
            " re_lu_115 (ReLU)            (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 131072)            0         \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 131073    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 527,681\n",
            "Trainable params: 527,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 512)               66048     \n",
            "                                                                 \n",
            " reshape_11 (Reshape)        (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_77 (Conv2D  (None, 4, 4, 128)        262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " re_lu_116 (ReLU)            (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_78 (Conv2D  (None, 8, 8, 256)        524544    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " re_lu_117 (ReLU)            (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_79 (Conv2D  (None, 16, 16, 512)      2097664   \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " re_lu_118 (ReLU)            (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_80 (Conv2D  (None, 32, 32, 1024)     8389632   \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " re_lu_119 (ReLU)            (None, 32, 32, 1024)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_81 (Conv2D  (None, 64, 64, 1024)     16778240  \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " re_lu_120 (ReLU)            (None, 64, 64, 1024)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_82 (Conv2D  (None, 128, 128, 1024)   16778240  \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " re_lu_121 (ReLU)            (None, 128, 128, 1024)    0         \n",
            "                                                                 \n",
            " conv2d_transpose_83 (Conv2D  (None, 256, 256, 1024)   16778240  \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " re_lu_122 (ReLU)            (None, 256, 256, 1024)    0         \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 256, 256, 3)       27651     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,702,531\n",
            "Trainable params: 61,702,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n",
        "    def get_gan():\n",
        "      return GAN(name='DC_GAN_COVID19_Chest_XRay_COVID')\n"
      ],
      "metadata": {
        "id": "94FsJOSmdfQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        imageFolder = 0\n",
        "        for i in range(self.num_img):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save('/content/gdrive/My Drive/Data_Augmented_COVID_19_Chest_COVID' + '/' + \"generated_img_%03d_%d.png\" % (epoch, i))"
      ],
      "metadata": {
        "id": "SG_0w-qwdjh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 136  # In practice, use ~100 epochs\n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(epsilon=1e-8),\n",
        "    g_optimizer=keras.optimizers.Adam(epsilon=1e-8),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "history = gan.fit(\n",
        "    train_generator, epochs=epochs,steps_per_epoch=1, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        " \n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_COVID_19_Chest_COVIDModel/Generator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_COVID_19_Chest_COVIDModel/Discriminator',save_format='tf')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "TJVQ4Dg4dq6t",
        "outputId": "8fa345e9-c32a-4b6b-eee3-0ea58689e979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/136\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-3a8d3e6b57c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m history = gan.fit(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGANMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-143-2ba5efad3126>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, real_images)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Sample random points in the latent space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mrandom_latent_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"<ipython-input-143-2ba5efad3126>\", line 22, in train_step\n        batch_size = tf.shape(real_images)[0]\n\n    ValueError: Shapes must be equal rank, but are 4 and 2\n    \tFrom merging shape 0 with other shapes. for '{{node Shape/packed}} = Pack[N=2, T=DT_FLOAT, axis=0](IteratorGetNext, IteratorGetNext:1)' with input shapes: [?,?,?,?], [?,?].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDozq0-8d8Nk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}