{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-KAqwHSkFqu",
        "outputId": "460ce053-f505-4ca2-e56f-f3c021e9654b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            " COVID\t\t\t      Normal.metadata.xlsx\n",
            " COVID.metadata.xlsx\t      README.md.txt\n",
            " Lung_Opacity.metadata.xlsx  'Viral Pneumonia'\n",
            " Normal\t\t\t     'Viral Pneumonia.metadata.xlsx'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (23.0)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls \"/content/gdrive/My Drive/COVID-19_Radiography_Dataset\"\n",
        "!pip install pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4JUZUnIjArU"
      },
      "outputs": [],
      "source": [
        "import keras \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from IPython import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from enum import Enum\n",
        "from glob import glob\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import gdown\n",
        "from zipfile import ZipFile\n",
        "# for reproducibility - ref https://machinelearningmastery.com/reproducible-results-neural-networks-keras/ and https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed\n",
        "np.random.seed(9)\n",
        "tf.keras.utils.set_random_seed(10)\n",
        "\n",
        "# loading data from gdrive\n",
        "chest_xray_dataset = os.path.abspath(\"/content/gdrive/My Drive/COVID 19 CHEST XRAY/images\")\n",
        "chest_xray_dataset_annotations = os.path.abspath(\"/content/gdrive/My Drive/COVID 19 CHEST XRAY/metadata.csv\")\n",
        "radiography_dataset = os.path.abspath(\"/content/gdrive/My Drive/COVID-19_Radiography_Dataset/\")\n",
        "xray_covid19_dataset = os.path.abspath(\"/content/gdrive/My Drive/xray_dataset_covid19/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Gy_GXINDq0-8",
        "outputId": "41c7dd9c-189e-480a-a0a0-f2e0c12dfc46"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}\n",
              "setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@markdown #**Anti-Disconnect for Google Colab**\n",
        "#@markdown ## Run this to stop it from disconnecting automatically \n",
        "#@markdown  **(It will anyhow disconnect after 6 - 12 hrs for using the free version of Colab.)**\n",
        "#@markdown  *(Colab Pro users will get about 24 hrs usage time)*\n",
        "#@markdown ---\n",
        "# taken from https://colab.research.google.com/github/justinjohn0306/VQGAN-CLIP/blob/main/VQGAN%2BCLIP_%28z%2Bquantize_method_with_augmentations%2C_user_friendly_interface%29.ipynb#scrollTo=XHyPd4oxVp_l stops colab disconnecting\n",
        "import IPython\n",
        "js_code = '''\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''\n",
        "IPython.display.Javascript(js_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "qSpMb9aHjQT4",
        "outputId": "990d4f05-c57a-442e-c4cc-08d00ac3e719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7232 files belonging to 1 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-76ac95d0f213>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  ax = plt.subplot(2, 2, i + 1)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHEAAABxCAYAAADifkzQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2da2/byrWGFynqLlt2vJO0G7so0G/9/z+hP6Pol92iQJDEtu538nzIeZZeLg8lRQ7acwIPIFiWyOHMur7rnSGVVVVlb+3/d8v/2wN4a69vb0r8CdqbEn+C9qbEn6C9KfEnaG9K/AlacerLLMt+SP2R57m1Wq0f0ZWZmWVZ5n3meW7tdtvfd7tdu7u7s5ubG/v111+t2+1ap9Px44ui8D6yLLN+v2/tdtu63a6PcbPZ+PdFUdjhcLD9fl+7rplZVVV2OBzs8fHR1uu17fd7fy0WC9tsNrZer+1f//qXPT8/2/Pzs1HS0X+WZS/mV1XVi+O22+3LA/+3nVTif7rpwGPjszzP/YXiiqKwVqvlSsqyzMqytN1uZ+12u3Zeqg8zs+12a+12u3ZcVVW22+18XHxH//v93rbbrZVlmRwzfZRlaWZmrVbLDofDjxKXt/+YEq8hFRCM/kXQKE09rNVqWafTsSzLrKoq22631u12LcsyP1bfc47Z0fuKorA8z60sS1ci5+AVeZ7bbrez/X5vq9XKlaSK1PcortVquZchj6qq/NhriZdz4fS7Oms6/nv6UYWpx/C/eosqkZDabrddEfv93g6Hg3uKekWe53Y4HNwY+v2+ZVlmh8PBNpuNbbdb/77b7dbC6uFwsN1uZ4fDoeZZKJ7+UTKKbrfb/3lP/F4lnjonZWXxWM0TqbCJ98TPVXHaBzlrv9/XxqHKLMvSz+N7lLPf790rOU7PR2n8jS/yI/Mxs5qXn5LNJd/RTipRc8OpdumAzNKK0+spoIiKiyGUvwCXGH7Ji5vNxobDYe1zrnM4HDxcMn68jbngeb1ez5XAsShdFYoR7HY722633jfK/N4Qeu6Y/xqwUY/hhZJQYgp9nvPKmPNQ1Ha7taIorCgKFyLv+R9FdDodz63qsShns9nYfr/3z2i8r6rKlsulH9duty3LMvds5q/G0NRe7YmnWuy86WKpZB/DpkL3FOJUJarS4meqXAU7KFIFeGpOHGf2EowQRuOc1GsxGpQa83pKZqn38W9T+yGe2HSxqDR9H5WHB6kCyHVYMn0QQulPPZhakdqP/kCZ9AfyJBQTPquqcvRZlqUNBgOfm6JKDAgUTIje7Xa2Wq1suVy64QCKqqrycdLwZnL4OZmm2ncrMV5I/4/h8ZQCU6BF0WWn06nVfanzVIkorNfr+XjwIupFBS2EaYSLEsqytNlsVuuXMaIsjiXvoYjtdusKJESroRZFUfNixq9gB4Wa2QsAdLUSz1lHCphElJhSsHqfhlD1Ps1z0WsV7XE83teEFhVJ6pz4HGGuVquax8Z5omyUp2iU+jEqKYZUPF4dQUshPf9clfAqT4xhUb0klfe0qTKaQijXUgCjfQFUer3eiz7MzL5+/VoTGrVdt9s1M7P9fl+j2/Dc7XbrQsZYEDBjWa1WXoagTOrBWOvSN0bJd4po9Vj1duZ4tRJjuOTil4TF6EWqRASkSuQv78kfKURKf4RQ8mNVVbZYLGy9Xttut7P1eu3nDYdD63Q6rrQsyzycaigty9I6nY57NkLVmnO329l8PncFbjYb2+12NSOPpYTKij41mjAO5Zj5/9VKbFKghrdTyDLWbwrpNbTGMiEqOBqL5quiKLy2W61WNpvNbLVavchHKA6loDiuh6LivFEuXCnEtoIZcln0QvWyaNSKbDVVqYw0/1+txFQYi8LXug4KSwlpBMGkIvWkk6T1er1aiaFjIIQqypxMJrZerx1glGXpKxiEaBTFdWBTuAYK+vTpk/V6Pev3+9bv9500WC6Xtt1u/TgETSSgrOA6kSlS6m2/37tyVDYq36qqaunhKiWqF8QQiiCB84PBwD1jvV778VoeKMORAkcovSiKGirUEKroVZkSiG4sX4kCvmPsCB/hMK7FYmHz+dw2m41f1+wInhQE8T/KQ5kanmMawavUkJh3fM8YMbCrlagKiMV0p9Oxm5sbGw6H1uv1bDwe22AwsFarZZ8/f64tv/BSOK8hTRXZ6/Xce1LhBC9vt9u2WCxcIN1utwbVeY8lU1YosOh0OrUSYT6f23Q6dXZHi3UdoyoBj8uyzAaDgYfWVqtVIwZ0LhElK/jTcKqp4Golarhst9vW6XSs3+87SOj3+w4Wbm9vXcCdTsfDDoImfGAUsS6KYTLmDvVQM7Pdbmez2czX+1CGmfm1tZak7qSvbrdrg8HAgdDz87NNJhNfzMUgd7ud8680ci9KIPSv12vrdruOlukbj2KuzIW8quQ6SsZ4kPvVSlRLgE/sdDo+CKXEyrKsCY5zB4OBW7oqB6FrWNG6MbWOR9/b7dZms5ktl0u3fO1DSwGzem5Xb4LLRHAYUavVstFoZIPBoNYHhPZ+v/fzQab0PR6PPYSDXs2OSBMkSjjWqKT1qjrRq4CNhk48hLAVazyEqfkDkAMs1wVbJhZBDkpcLpc+eF0Ixgu+fv3qBDOr8pFAR6mK9FCIggvO1ShAqlDlr1Yrnyd9kEcJ6Tc3Ny4zlB3pOp03ORRQpEatqP9qJY5GI6+XVEh4YqfT8clwPOEOeksJZKWnVBAIfTweu3XjBXme22AwcGP5+9//7sJkvQ7vSJUs+/3e1uu1jUYj74N9NbFuo7XbbRsOhzYajWw6nfr8NBpArY1GI48a/X7flsullWVpHz58sF6vZ5vNxp6enmp0H+UK8kDZhFQMDTm/GtjQkZYQINKIXlF2lmU1+I4XMPAIQLQ/zRE6CegwPAEBKIFMDtFlLP2c8SuwwJiKovCCnTwE2qQG1ZYCZ3ENkmtiZLojAMUpEIr1cyQIrlIiYEA9sd1ue8jQi3AMoEHBBYNaLpc12I31j8djDz866Ha77WXMbDazx8dHMzuGSF3j63a71u12PXrQh1JzXDvSZWVZWr/f98+pD7vdriuaMoJxc11dE1ytVh41lsul3d7e+mK0Rg4FSnmeOzjTlRENpa8Kp8qIUDgzuUiz9Xo9L4o5hskoF4hSbm5urCxLm8/ntlwubT6fHwdVFDYYDDxHPT09OZLT/BIjAeBBQ5dSW7zYTwMtp4Ci2+3aw8ODHQ4He3p6qgGn1Wr1grHB2Dqdjg2HQxsMBm5E2+3WzMyGw6EbiJLreZ47UNxsNnY4HGwwGNQI9fF4bKPR6Holav5joMBnzT2xxtFw2G63PXSgWIyiLEvPLShZi3m8Zr1e19bsuKaSxFyb/KRAxqxepxEdzI5hkflqLiW8mh3RLGFR+9f62cxeeChzURoR79K9QWoweCbOc7USCZHkh16v5yVDLMQJCVmW2Waz8XPG47GHj4eHByvL0msxSgWKckAMtSdrc9Bp5BmExmoDuauqKpvNZk4YaHhC2AgagPP161fb7/e15S9yGMaIgWJISrqrQjkHA1GkrsZJGw6Htt/vHd2u1+vaSgjyfXVOVA/EKuK2A7P6ygSDHgwG7intdtu9rqoqzwl3d3cemiiUW62WK5CimlC9Xq9flCgAA4RK/9Pp1Pr9vhfuGCaC1ILdzDwU6tZCzZvD4dBzmyJLM3MvVZCGLCj46ReAA5ihLoVI4XplWdp4PLbhcHi9EjWUws4oo6BhSZXKwHSQZlbLIxwPoGEJiMkrEABcwJ6oEiOtpeUAYERXORi3lkYKzgh9Gm4xPLyK8Wo5gJFxDv0S4uFvaYqQI3pWJfZ6vdpuhe9WIlbV6/Xsj3/8o1XVt11cCFpDlS490Qh3DFjD1M3NjYcg5Q6ZGEwI5wF+yJP0jcJU6LomSR2pAlcSXD0Uo9Uxq9DpH2NqtVo2HA5tvV7bZrOxyWRis9nMQzUvjAtDJVIRnlXxSlSYmcv6aiXqMg4XiMBArVupLq3vNpuNr+9xrpK8sEC9Xq+WA9l0pMBG0SRhtN/v1yar4yBE397eulEiMF2J0PCH16pHmJktFosaY7Pdbm29XtfIbs2fvC+Kwo+9v7+veXaMTCxxac34qhIDRcDCqLJUEXyuQEKVTUjRmpGG5VGDsq9TN99Cr5mldxtwfkTMWruS0zHI6Im6BKQhVNHwdrv1ME84Xq/XXhYoJmD8EB/qvVoHgrJ12QsjUdrzVUq8u7uz9+/f23K5NDPz8EBDoMqpIpQoTFUeVBL8JYwJHjCZTGorE0yaWpBkT+ilv/V6XQunqqiiKKzf778oaZQD1hUbM/P6d7/f23K5tKenJ3t6evLcqfO8u7urLQxjQMwjRiKiCbkUADmfzz2P/vLLL/b+/fvrlfiHP/yhthanuUtDF0rTFQKOUViu5LeyMvSxWCwckeriaq/X88nikdqX2XEjk6JlrqN0HhZOH7rqoaWB3kSjjAqhmWihkUj37yhw0nCKwbXb7Zpy9doQ7/f3917SXa3E9+/fezjTop4LahKOBT8CVQGklKzLMygwolhd1lFUqC0ah/6vOUuvrYqM63hQbngJtST03ZcvX9xD+U6LejwNMEN+X61W3r+S9mqUsFUfP36slTFXKZEQGsnkOPks+7boipCU71MQkRow7AhcK8fqyvpms6kxIORKhfDK8KAg7k9E+NSM3NXLWFPRBAUgQFLLarWyxWJhnz9/fkF4U5cS2vmrO+FAr6Bzrqlgilw6mUzs9vbW7u/vr1eiWZ1zjOEqegUK0s1AMVRwnB7PsXotXW0gzyBUJkuf5LkIeuhHQ6V6SMqjVYGxT/qDQy7L0skHzmHcbOJSmbHMBlulCozOQd8RS3y3EpUTVEUyUaWZNLaTzBloqp5TxRKSIqlOn3oXUhRwnuc2Go18mUoVA7rWfIwBqHJQgtaW2k9E4Z1Ox0ajkYMqVeJqtfK5aAmlaBZ6jT5QvvLBVVV5WfaqcKrsRb/fd65T6xasTWsewmEsC3SBWDfmcgxeBhJE4IyDsERtOJ/PndVACePx2AXGPRUIEU+ICqShXMIZnylvyzn39/eWZZk9Pz97vUk62O/39vz87DsAQZqQ/qvVyh4fH208HjtDgwLpQ8fzQzxRY7Z6knqYsjepz2JIVepLc1jciBuvo/QV77W47/V6rgSIcIxKQ5aO7RRQUgFqJOA7DZep+0CYq85fIwKRDu+P81Z+uqldtFGq1WrZZDIxs6N3xpzI4BRa62cIRhGpAoeqqnxrPJ6KAbEmmWXfNiJhzbe3t44K1eBWq5WZmb17986Gw2FtAxTCjyhVx8vY8G6ECG2YunGG5TXCqRqKgi7q0ao6EuMwVbGUwwBexdh0Oh1fTVAPUGvRSfK9WpXWZbqfhvC2WCxsNpv5Ai35dbVa+QQeHh6cugMxxwIdY+l2u/4kjPv7e19dhxFqtVq1vaa6nke/utpAvuJaRVHYcDj0VRiQZqvV8jkoWcBc+v2+17uMmXKDrZ4pYHbOC88qMS6CRlCiFq2fx3pMw4O+h2KD7MZLabFg13oRBdCnrl7QD9yvUoIKmFRQav0xDZDPmVucoxL/WnJhBDoPNZhYU2utHeV8tRKfnp6cpdBCXwfBRXQ7hAIDHYByq4TSxWJR266nFkzYYkvi7e2tgx722+htambmZLhyk3i/0m9VVdVWCzje7BgxYqrAqxgzClVkjcFQN2tILsvSRqNRja9VzhdjUaLjnALPKlH3e0bajUlpizmGz7QcoD82/vb7fReE7l7TdTUKYHIjXgj1ZXbc4pfnuRud7nfR8aoXKV1HX1rEx7RBmcD57EKoqsoeHx/t4eHBer2ec7gsOen2EhZ/dcFZr6G1uBrXVUpU64qeqJaqCkv91QEpdC/L0jlEjtGFYAVKSh6YHflI2B4sGa/TbZYxfMUX38VjUkqMigf9RlqQ0kiRJ2MlEuheHHWQKNMfgk4VnsccGGN8SsEcg6DjA3qUngLA6EPydFFX6Tsz8/VK3VPDuqGGt5gHFUUzdq3LuB5ChuDmphkK8ZubGzfQ8Xhs0+nUnp+f7f7+3ndEQPWBRvf7vU2nU1+xT+VgPn81sPnTn/7kO6H/8Y9/1PIAF1EhMAj9C7rDGAiNoDgKcMKp5hM8EFQXqTJQYZ7njgyHw6GDGfYEaZ5VtKxMiZYE+lLPgG6j8Kev5XLp5D3Gst1u7enpySaTiT+Bg2uSc9m+yMqGrmkqYHqVJ378+NFub29tPB7b77//7sKPCovQWFu0qtRKglJhIFENOShVb1DJssyGw6F73devX73EYPK6KKz1aFMqaPJQ/uoiuaJRooHeWKMbqqgVUTxhd7PZOOKm1lW5agq7Wom//fabLxHR6amloFQ4oj4jZBLiuCV7Pp97blOhsXGY6yE8ZU3ev39fIx/Ip9RpkMegPpSk72mpqKI8ph6jZLzWhrpzgDoX9MyGaM2nil7J3bp680PCaVEUNp/P7fPnz7VVdiYawUCq6Zb6PM99K+FsNnM2X4l0LQVUWFV15DS1RGGiuhMPodKXImplZBQMaehEkDHSaL2py1cInd0GGjJ57XY7WywWvs1fdzZMp9NaHo9g61WeWJbfttl/+vTpxQqBHpP6XAWi1rTb7VyJulcFJSucJlShNEWh7HgjdxCCsWzlS+M6oRbY6nUKwHQOmktVkYwR2bAZWDdY0T97bKABMQLk8e7du1pIjSj5VDupxL/97W8ORFJ5Ik4wBQYU9j8+Ptp0Oq096BVhZVnmjL8u2LLvBOTKncdm5oyPPjWYvIPn6kqMhni8UZedFG1r/tIak1CtW/wXi4WVZWl3d3ce0rMs8zxJrkThzItIweo/+5eooVWmVytRd2zHuikqMyot0kiwL+Q3tVQFK/QR1/y0KGbDU1zN1/Ii1rZNwtDcpOE2Ehv8hUxnSUu90uxYAjG2oih8WyN7TnUBmX298ZqXMDUXKVGtLVJuKSXGvELIwDqVGlPhafjRYpkooN+1Wt92uv3yyy81xSJQbnSNxT6GogIndGIIWhOmeM6yLB39Pj8/W1ke78sgjJKbKW/wdiIKfTFebsfTfK5yfjU61aJcJwT9BAuvuSTGdOA9+QzQoOQ1IQd6ipCqKJI+fvvtNxuPx/bhwwff1kgY1joRwjxGEA2rWurwOWlDUSPno5Qsy+zu7s4Wi4U9Pz97X8vl0jdNcetelmX217/+1SaTiW+uQn7KAMVIEAmKq5UY8xtNJxxrrmhBDFKXpxR96gvLjoJmMhomCbf0HR88pOt2TShPKTU9tkl4GvK0vgNQcS4RBKPVsamsmLOGbaKfXv9Vnqj1kXokk8VbODZemJCpG2SxaAbMWiL5Egg+mUxqK/26E537Hvh+uVzan//8Z7u9vf02qeJ4a7oaAu9jfmRMWtLoCgVN7zYmNJblcbOUgiXuFO52u7ZYLNzQCN1EFmpo5KoPcrq0nd3tRofkjjzPa8W5KgzBKLhYLBYeOnTwEfHpKkJZfruN7Pb21rIss6enJ88d+hAGs29U2N3dnd++hhdpRFBLV9gf8zuKj8hUIwoKxwvH47EVRWGz2cx+//13X9kvisKm06ktl0ubTqceHRgPVNxut7PPnz/74jVPG9HVmbha9N1KVEWqy8cdYSowfWm8160N6hG64KrhjHAE/L65uXlxi1ie57VHl8TVFgTRNC/9PqYARaZNRTgkd1mWzvHynS6l4cW6c1CP4xrK2Jwb/0VKjIUtA2IvDHkERcX7+3Ty+nhJHZROKG4S5nqDwcDu7u7sw4cPlmWZk+YQ4LqQqhbPmCMhkQpVhENNHWZWqzsZX+wTxPyXv/zF5vO5LRYL+/Tpk5+nxMRwOLSq+rYzTkEYt8Gx1T+G/6uVqFsEdY1PF035XjciKbTnIQXUSmbHTbScy2B1o6zWh4fDt4f+PD4+1n4+QQ1ChR/rzsiTashVMkINTz2SxlgUnFXVN9Jdyx3WSOfzuT8qDGCzWq38wRNKGdKXUoVKsFytRIW9qVpOwycK0DBGkifGRw4zgqFIj+kLxSNwDTtx5TuGaVWovk8BCJ1DfKni9HhCpN4ppc8LV8XsdruakZMy6FeNSOdytRJVEaCw2WzmggME6E01DADkqKw9e2lYaWCQTEiZkcVi4dBfnyvX6/U8PDNRBTSaa5oQHmnA7PgkSV14pmnuQ0kAOn0ODddmlaKqKnv37p1NJhObTqf2z3/+s1ZibTYb+/Lli/3666+12+g1Fysn+ypgo0sv3CVLXUMS1hCk63coS1codNVABcoglclXZcDAAAJ0FYGJq5cr45KyYjWWlKU3KT9VT3J8BD9m9ZJkNpv5UzIw/t3u268EjEYjdxbtS5/h+iolgirjr5Np2cFneu+DWX2xV0OvClIFRmGsTE1VVe59KjgNOTFUR6blnCJpTYBHQ78qknAZ0bICPeZEJEJueDUAERCnRqx9Xa1EM/PfemCRk4cRxUdm6qT0yRc6IGX12YrR7/ft7u7OWQ8EixViidykScjabrc+FnIjIVf5UVVGk6KaWjQc7YdcRihWA485mhWO4XDoO71VeZPJxEMq/SqZolsrU+3svlOKc024mpj1cwCQmTkXikJBdeQ17QvBo3QUx6R0IRYkh8IITUp663gQvApZjQWPj96UUmjqGI1IyvRoaFXgR50cDUMJeIxD08TVSnx8fHRrpCZj0KpEBRRKs0FoK/zmtjB9IhNgQJePAD/KziB0BTQoF4Yo7oZL5S5tqYI65UkIlGM1jehKCPJSxKmy0r1DXFNXchTtQuqnjOpiJS4WC3+EiC5iKoRXr+TiPAw9WibUmHqJ1nrczYuHac4hBOHF1FHUZUpKqDfr/xibhie1/qhYlKDj4L3ekq5AhLSgy3gKsvThv5PJxJW5WCwsyzL7+PGjR65okFcpkQHGBVYFKan/9f4KBoNXacIGeeJh7Kam/PBBSp2l9WgUknppqhaMHspnEWRFYiAV0ljY1tUUbfpZimhgcTlGl1jga5Rramc3SsXQCTqLK9pqbTw8Yb1em5n5pls9jp3QPAYSD+GaaslQX7o3k5zJRBUxK5o8Vzvq/h5tWnqkECx8KQ+mUGIEb1WCRK9HHmcrP0hWQ6ga3quUiMKU0ooWr0sprG6wFXG1WtnDw4Nl2fE2Lsjs0Wjk/SsY4aVUVpwEAmMsusLCuLUOVCXFckMBiAouxSgpFRhXYKjz8Ewij3KnoFgwQ/R80Hq80fZcO6tERZ+0GKJohNGqOt5YqfkKglxrQe1fAYUqRK8Ta05VvL7i2E4JIxWCTx2bqnUj2MGrYHj4LNadqeiGUZzzQNrFqxhq3bGsIM5Pp1Obz+dWFIW9e/fO2u223yfBPQmESwBNDMkqQN0BgCCit8RzT008Wnb0tKZzUu85n/BodtyeiRHrzj6ii95RxbghyJW+jEZ+ql3kiTE0xYsfDgf797//bXme+70KIFrCpkJlcgCC4DuF5fo3KjrSZTHU6/nqnTFsniOX9RytKeM4GB8gzuy44xsFc6NQpAvNjg86IhTH8u1V6LQJsakAKF71IeYU5WpdZlYbnJYaaiwqvBjemCAeEFFnasIpT7okz+g5qvzYRyQWIgmg9TA5MkaALMtquwHjWF+lREWmenHqIO6j0JCS53ntaf18FnOYKpSmk4vQW7+PaDGVr5tCZUqpTfxpZHxSkSH2p+CHYyG62+22PT8/e/2spdNsNnsx/0vbRT9Hq4uouoqRZZkvl3A/ntaCmk9TdVwMa/qZenAMWynFaWsKn6ljmxBoPDaG6VQDkOj/ZlbbNExZUVXHZ4qzxpjnuX358uXF81tfRYBrzkjtOdFakVDKZCMo0pzYJEh9qbWn4HZTmNP/T9FtfJ7iVJtaSqgRoepnaiCR3ODF7QmQGMvl0hF9jDpN7SIlKvvA8hK/1MYDW1X4cTkplbOUEoulQhRazDmMJwIexhzR3CklphAu/aiy4vhY+yPPuUCFKqMPiH2zI3FxOBz8Z4l0Ezbj17unz23TOLs9Q6kls29KHI1G/ruJ+lhnZXjU82ipOjDVmsCJel4kqVVwKZpMr5fyHu0nBT70+yYviWBMPVKdgT6q6ts+248fPzrrgyOo0ZzzxrOeiBJVENR8emMMSkyBmBRr0pTAY67ks9QxKaZFQ7Fuw2jqNzUm7TOlzFRfsV9VoEYPBXZEtF6vZ5PJxImSOIZz7exuN0IG/Ce/WKr3AqoXpkJXivFRITYJOuWt8dhULox5KPatTcOe9s+19akYCjZ0eSxVb+pmMgVpGtXUyLgt7vHx8cWNROfaRT8zxO1Xg8HAi3d1eyadAiepfNgESGKI1NZk+ecUGfuIn0dF81k8p4lZOhV2I7jRcZsdyxA1HH4iMOXhTe3ip/EPBgMbDAb+K2Q6mSjESBdFQSgibBKUfk9Tr1Uh6GaraFj0E4GR9q8sSfw8xZOmQnA0Mh2TzkfnFCNAnuf+1CxdYH5ViYHybm5u/NmdlBYpBWi857tYY6oS+F9XMZomHSePoGipMem19bqRLdJ8FVuqzEqNhaaGmrq2GoA+OkwVRWri8WP6DNRUu/gHv/R3JVLAIoWoYq5oguynFJhSYlP4OnWenqMeGj04hr+m0iXl2anxc2wKhDX1yft4d1dTO6lEHu/Y6XT819R01V2VoJ7AIGJRrALj/FQ5EsN1FI7+1cnH/JtSth4XWwqgpBqIXT0+NRa93qlSJl5fn/kab5lItZNK1J+wQ4FQS6AuXTJhIIQHteqo6LjElVJWJJfpJwosRcelQA/H6PkpgBJLk6gYxqV7b2g671T0SHl6nh9/S0oL+yw7Pj35VLvoAX2R90zxoUw0FsqqpBSaTXlbPE9bU1iNYSp+1+SVjPnU97HPOF/+qvEiv1TkiOPV/M3cNWq9KpzqZla1Pmg1HaRuWVDlRiVqPzqJOMFIlqcm3tRSofZU7kmFvpQx6DlxdSduz1AZNo37lKHjnaScU+2sEgE3qswYPquqvo9St2Skcp0Ki+SuQjuXB+MxKZYjWneTQqJymzwujifSZ8wBY9abYZQk0LHTf6oUYWx6W0RTu/h5pwpgmkKgDlItCwGljo3v4yRTf/V9E10W3587NgVIToVZnV8EVrGUStWmqfGlrkSOn8sAAAF0SURBVPHqcKrb4mm6/KQD1W0H0UtTg41KSC1TnQubHHOKFYlKiTu54zx0XKdaCgvwudnx5xWUlYkIXb0ZL463eqcWEmK7SIlxdSI29TydYNMrtiYAcArUxNZUh2l+a2op4HLquNS11RD1M5ibVOhMGTvHXzIe2kWbh08xKvr+lMIiWFHLTfV7qUfQUp4Xv2v6ns9Ttdyp46KXx8I/lQ6a5sMxWt6cGq+2s7+LoT/WTFOPTD3gzuw8SXwK8PC6VIGxv6Z2SWiO79WjdXwpFkaP1/epucZzY32J1zZFP21nGRt9ACyKiUU7A9LlqCiI6IlxYiklp3JWFAbfp7w5Fbpia8qHcQ5xDLEuTh0TAY4eE0O4fp7iUU+1swQ4Kxn6ZIt4q1m8YPQiVWAq3DblyiZFngJKTeen2inFNo0pRZPFz5uObbq2vo/GfQl3mn1PyHpr/zfbZZv939r/6famxJ+gvSnxJ2hvSvwJ2psSf4L2psSfoP0PLGlHtwJINdUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load images\n",
        "image_size = (64, 64)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "dataset = keras.utils.image_dataset_from_directory(\n",
        "    radiography_dataset + '/COVID', label_mode=None, image_size=image_size, batch_size=32\n",
        ")\n",
        "for images in dataset.take(4):\n",
        "  for i in range(1):\n",
        "      ax = plt.subplot(2, 2, i + 1)\n",
        "      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "      plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TndIIeA7R5IK"
      },
      "source": [
        "# Code taken from ref https://keras.io/examples/generative/vae/ and refactored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NKKXZDF3P5o"
      },
      "outputs": [],
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRqfi82oD8q3",
        "outputId": "a1ca30b8-366a-4454-9d9c-29f769d5f36d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 32)   896         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 64)   18496       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 16384)        0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 16)           262160      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 2)            34          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 2)            34          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 281,620\n",
            "Trainable params: 281,620\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 2\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(64, 64, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl-lUO8PnvxI",
        "outputId": "c61dab2a-6ef0-470f-d53c-41a45cfe97d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              3072      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 512)        295424    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 512)      2359808   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 1024)     4719616   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 2048)     18876416  \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 64, 64, 1)        18433     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,272,769\n",
            "Trainable params: 26,272,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(4 * 4 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((4, 4, 64))(x)\n",
        "x = layers.Conv2DTranspose(512, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(512, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(1024, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(2048, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "\n",
        "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crjHnHiplTek"
      },
      "outputs": [],
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.mae(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "    def get_vae():\n",
        "      return VAE(name='VAERADIOLOGYCOVID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "15ivoe-vnzsC",
        "outputId": "14dfd992-cbe7-49f2-acb9-992438cddc45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/226\n",
            "1/1 [==============================] - 46s 46s/step - loss: 431955.8125 - reconstruction_loss: 431955.8125 - kl_loss: 1.0532e-04\n",
            "Epoch 2/226\n",
            "1/1 [==============================] - 45s 45s/step - loss: 404551.1562 - reconstruction_loss: 404551.0625 - kl_loss: 0.0935\n",
            "Epoch 3/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 444348.8750 - reconstruction_loss: 444348.8750 - kl_loss: 7.8321e-05\n",
            "Epoch 4/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 388715.4375 - reconstruction_loss: 388715.4375 - kl_loss: 7.0125e-05\n",
            "Epoch 5/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 418791.3125 - reconstruction_loss: 418770.9062 - kl_loss: 20.3913\n",
            "Epoch 6/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 436191.3750 - reconstruction_loss: 436191.3750 - kl_loss: 6.2019e-05\n",
            "Epoch 7/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 342143.1875 - reconstruction_loss: 342143.1875 - kl_loss: 6.0767e-05\n",
            "Epoch 8/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 371388.3750 - reconstruction_loss: 371388.3750 - kl_loss: 5.9068e-05\n",
            "Epoch 9/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 411286.9062 - reconstruction_loss: 411286.9062 - kl_loss: 5.7161e-05\n",
            "Epoch 10/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 372692.4375 - reconstruction_loss: 372692.4375 - kl_loss: 5.4955e-05\n",
            "Epoch 11/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 391460.6875 - reconstruction_loss: 391460.6875 - kl_loss: 5.2691e-05\n",
            "Epoch 12/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 375268.0312 - reconstruction_loss: 375268.0312 - kl_loss: 5.0366e-05\n",
            "Epoch 13/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 393698.1875 - reconstruction_loss: 393698.1875 - kl_loss: 4.8101e-05\n",
            "Epoch 14/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 455202.1875 - reconstruction_loss: 455202.1875 - kl_loss: 4.5896e-05\n",
            "Epoch 15/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 443641.5625 - reconstruction_loss: 443641.5625 - kl_loss: 4.3690e-05\n",
            "Epoch 16/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 424684.2812 - reconstruction_loss: 424684.2812 - kl_loss: 4.1664e-05\n",
            "Epoch 17/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 335445.2188 - reconstruction_loss: 335445.2188 - kl_loss: 3.9697e-05\n",
            "Epoch 18/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 422947.1875 - reconstruction_loss: 422947.1875 - kl_loss: 3.7968e-05\n",
            "Epoch 19/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 398512.1250 - reconstruction_loss: 398512.1250 - kl_loss: 3.6240e-05\n",
            "Epoch 20/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 466311.8438 - reconstruction_loss: 466311.8438 - kl_loss: 3.4809e-05\n",
            "Epoch 21/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 386559.1250 - reconstruction_loss: 386559.1250 - kl_loss: 3.3438e-05\n",
            "Epoch 22/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 412530.6562 - reconstruction_loss: 412530.6562 - kl_loss: 3.2306e-05\n",
            "Epoch 23/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 439084.1250 - reconstruction_loss: 439084.1250 - kl_loss: 3.1352e-05\n",
            "Epoch 24/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 412194.3750 - reconstruction_loss: 412194.3750 - kl_loss: 3.0458e-05\n",
            "Epoch 25/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 395803.0625 - reconstruction_loss: 395803.0625 - kl_loss: 2.9802e-05\n",
            "Epoch 26/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 495234.5000 - reconstruction_loss: 495234.5000 - kl_loss: 2.9266e-05\n",
            "Epoch 27/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 409325.8125 - reconstruction_loss: 409325.8125 - kl_loss: 2.8789e-05\n",
            "Epoch 28/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 411134.7812 - reconstruction_loss: 411134.7812 - kl_loss: 2.8491e-05\n",
            "Epoch 29/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 423047.5625 - reconstruction_loss: 423047.5625 - kl_loss: 2.8253e-05\n",
            "Epoch 30/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 402695.4062 - reconstruction_loss: 402695.4062 - kl_loss: 2.8044e-05\n",
            "Epoch 31/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 416457.5000 - reconstruction_loss: 416457.5000 - kl_loss: 2.7895e-05\n",
            "Epoch 32/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 407469.0000 - reconstruction_loss: 407469.0000 - kl_loss: 2.7835e-05\n",
            "Epoch 33/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 376639.2500 - reconstruction_loss: 376639.2500 - kl_loss: 2.7716e-05\n",
            "Epoch 34/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 421214.0938 - reconstruction_loss: 421214.0938 - kl_loss: 2.7657e-05\n",
            "Epoch 35/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 449859.6562 - reconstruction_loss: 449859.6562 - kl_loss: 2.7597e-05\n",
            "Epoch 36/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 346116.1875 - reconstruction_loss: 346116.1875 - kl_loss: 2.7448e-05\n",
            "Epoch 37/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 445205.1250 - reconstruction_loss: 445205.1250 - kl_loss: 2.7329e-05\n",
            "Epoch 38/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 415843.4688 - reconstruction_loss: 415843.4688 - kl_loss: 2.7090e-05\n",
            "Epoch 39/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 439222.7500 - reconstruction_loss: 439222.7500 - kl_loss: 2.6911e-05\n",
            "Epoch 40/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 432081.0625 - reconstruction_loss: 432081.0625 - kl_loss: 2.6643e-05\n",
            "Epoch 41/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 417743.4062 - reconstruction_loss: 417743.4062 - kl_loss: 2.6315e-05\n",
            "Epoch 42/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 422507.2500 - reconstruction_loss: 422507.2500 - kl_loss: 2.5988e-05\n",
            "Epoch 43/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 378951.9688 - reconstruction_loss: 378951.9688 - kl_loss: 2.5570e-05\n",
            "Epoch 44/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 420072.6562 - reconstruction_loss: 420072.6562 - kl_loss: 2.5123e-05\n",
            "Epoch 45/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 388743.4375 - reconstruction_loss: 388743.4375 - kl_loss: 2.4676e-05\n",
            "Epoch 46/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 402726.4688 - reconstruction_loss: 402726.4688 - kl_loss: 2.4229e-05\n",
            "Epoch 47/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 419438.9062 - reconstruction_loss: 419438.9062 - kl_loss: 2.3693e-05\n",
            "Epoch 48/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 426509.3438 - reconstruction_loss: 426509.3438 - kl_loss: 2.3127e-05\n",
            "Epoch 49/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 423037.7500 - reconstruction_loss: 423037.7500 - kl_loss: 2.2590e-05\n",
            "Epoch 50/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 401527.0312 - reconstruction_loss: 401527.0312 - kl_loss: 2.2084e-05\n",
            "Epoch 51/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 448661.4375 - reconstruction_loss: 448661.4375 - kl_loss: 2.1517e-05\n",
            "Epoch 52/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 415557.4375 - reconstruction_loss: 415557.4375 - kl_loss: 2.1011e-05\n",
            "Epoch 53/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 443959.6250 - reconstruction_loss: 443959.6250 - kl_loss: 2.0474e-05\n",
            "Epoch 54/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 408609.6875 - reconstruction_loss: 408609.6875 - kl_loss: 1.9968e-05\n",
            "Epoch 55/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 431356.7812 - reconstruction_loss: 431356.7812 - kl_loss: 1.9461e-05\n",
            "Epoch 56/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 426154.6875 - reconstruction_loss: 426154.6875 - kl_loss: 1.8984e-05\n",
            "Epoch 57/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 377666.8125 - reconstruction_loss: 377666.8125 - kl_loss: 1.8507e-05\n",
            "Epoch 58/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 405964.1562 - reconstruction_loss: 405964.1562 - kl_loss: 1.8030e-05\n",
            "Epoch 59/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 394668.1562 - reconstruction_loss: 394668.1562 - kl_loss: 1.7643e-05\n",
            "Epoch 60/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 342498.9375 - reconstruction_loss: 342498.9375 - kl_loss: 1.7196e-05\n",
            "Epoch 61/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 446746.0625 - reconstruction_loss: 446746.0625 - kl_loss: 1.6779e-05\n",
            "Epoch 62/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 351808.8125 - reconstruction_loss: 351808.8125 - kl_loss: 1.6361e-05\n",
            "Epoch 63/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 461433.1875 - reconstruction_loss: 461433.1875 - kl_loss: 1.6004e-05\n",
            "Epoch 64/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 445252.7500 - reconstruction_loss: 445252.7500 - kl_loss: 1.5646e-05\n",
            "Epoch 65/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 431003.0000 - reconstruction_loss: 431003.0000 - kl_loss: 1.5259e-05\n",
            "Epoch 66/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 490823.3438 - reconstruction_loss: 490823.3438 - kl_loss: 1.4961e-05\n",
            "Epoch 67/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 429493.3750 - reconstruction_loss: 429493.3750 - kl_loss: 1.4603e-05\n",
            "Epoch 68/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 446507.5625 - reconstruction_loss: 446507.5625 - kl_loss: 1.4246e-05\n",
            "Epoch 69/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 391364.5312 - reconstruction_loss: 391364.5312 - kl_loss: 1.3888e-05\n",
            "Epoch 70/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 463047.6875 - reconstruction_loss: 463047.6875 - kl_loss: 1.3590e-05\n",
            "Epoch 71/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 440449.7812 - reconstruction_loss: 440449.7812 - kl_loss: 1.3232e-05\n",
            "Epoch 72/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 383302.3438 - reconstruction_loss: 383302.3438 - kl_loss: 1.2934e-05\n",
            "Epoch 73/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 410275.2812 - reconstruction_loss: 410275.2812 - kl_loss: 1.2636e-05\n",
            "Epoch 74/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 391642.7500 - reconstruction_loss: 391642.7500 - kl_loss: 1.2338e-05\n",
            "Epoch 75/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 434212.6250 - reconstruction_loss: 434212.6250 - kl_loss: 1.2040e-05\n",
            "Epoch 76/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 439954.4688 - reconstruction_loss: 439954.4688 - kl_loss: 1.1742e-05\n",
            "Epoch 77/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 419389.6875 - reconstruction_loss: 419389.6875 - kl_loss: 1.1444e-05\n",
            "Epoch 78/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 394465.0312 - reconstruction_loss: 394465.0312 - kl_loss: 1.1206e-05\n",
            "Epoch 79/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 400807.3750 - reconstruction_loss: 400807.3750 - kl_loss: 1.0908e-05\n",
            "Epoch 80/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 385498.6875 - reconstruction_loss: 385498.6875 - kl_loss: 1.0610e-05\n",
            "Epoch 81/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 438177.1562 - reconstruction_loss: 438177.1562 - kl_loss: 1.0312e-05\n",
            "Epoch 82/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 397600.9375 - reconstruction_loss: 397600.9375 - kl_loss: 1.0073e-05\n",
            "Epoch 83/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 394257.3125 - reconstruction_loss: 394257.3125 - kl_loss: 9.7752e-06\n",
            "Epoch 84/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 461257.6250 - reconstruction_loss: 461257.6250 - kl_loss: 9.5367e-06\n",
            "Epoch 85/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 443010.0000 - reconstruction_loss: 443010.0000 - kl_loss: 9.3579e-06\n",
            "Epoch 86/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 404381.7500 - reconstruction_loss: 404381.7500 - kl_loss: 9.1195e-06\n",
            "Epoch 87/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 491670.0312 - reconstruction_loss: 491670.0312 - kl_loss: 8.8811e-06\n",
            "Epoch 88/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 357120.8438 - reconstruction_loss: 357120.8438 - kl_loss: 8.7023e-06\n",
            "Epoch 89/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 379669.3125 - reconstruction_loss: 379669.3125 - kl_loss: 8.4639e-06\n",
            "Epoch 90/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 395927.1875 - reconstruction_loss: 395927.1875 - kl_loss: 8.2552e-06\n",
            "Epoch 91/226\n",
            "1/1 [==============================] - 45s 45s/step - loss: 365663.3125 - reconstruction_loss: 365663.3125 - kl_loss: 8.0466e-06\n",
            "Epoch 92/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 426324.3438 - reconstruction_loss: 426324.3438 - kl_loss: 7.8678e-06\n",
            "Epoch 93/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 358330.5625 - reconstruction_loss: 358330.5625 - kl_loss: 7.6592e-06\n",
            "Epoch 94/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 401073.5312 - reconstruction_loss: 401073.5312 - kl_loss: 7.4804e-06\n",
            "Epoch 95/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 336770.6562 - reconstruction_loss: 336770.6562 - kl_loss: 7.3016e-06\n",
            "Epoch 96/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 397909.3750 - reconstruction_loss: 397909.3750 - kl_loss: 7.0930e-06\n",
            "Epoch 97/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 433692.5312 - reconstruction_loss: 433692.5312 - kl_loss: 6.9439e-06\n",
            "Epoch 98/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 458728.4062 - reconstruction_loss: 458728.4062 - kl_loss: 6.7651e-06\n",
            "Epoch 99/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 426404.6875 - reconstruction_loss: 426404.6875 - kl_loss: 6.5863e-06\n",
            "Epoch 100/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 326340.8438 - reconstruction_loss: 326340.8438 - kl_loss: 6.4373e-06\n",
            "Epoch 101/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 388886.0000 - reconstruction_loss: 388886.0000 - kl_loss: 6.2585e-06\n",
            "Epoch 102/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 425816.7812 - reconstruction_loss: 425816.7812 - kl_loss: 6.1393e-06\n",
            "Epoch 103/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 408041.2188 - reconstruction_loss: 408041.2188 - kl_loss: 5.9903e-06\n",
            "Epoch 104/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 444956.1562 - reconstruction_loss: 444956.1562 - kl_loss: 5.8413e-06\n",
            "Epoch 105/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 467756.3125 - reconstruction_loss: 467756.3125 - kl_loss: 5.6922e-06\n",
            "Epoch 106/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 459045.3125 - reconstruction_loss: 459045.3125 - kl_loss: 5.5432e-06\n",
            "Epoch 107/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 387111.2500 - reconstruction_loss: 387111.2500 - kl_loss: 5.3942e-06\n",
            "Epoch 108/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 400801.3125 - reconstruction_loss: 400801.3125 - kl_loss: 5.3048e-06\n",
            "Epoch 109/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 421225.0312 - reconstruction_loss: 421225.0312 - kl_loss: 5.1558e-06\n",
            "Epoch 110/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 465776.3438 - reconstruction_loss: 465776.3438 - kl_loss: 5.0366e-06\n",
            "Epoch 111/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 438178.4375 - reconstruction_loss: 438178.4375 - kl_loss: 4.8876e-06\n",
            "Epoch 112/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 435391.9375 - reconstruction_loss: 435391.9375 - kl_loss: 4.7684e-06\n",
            "Epoch 113/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 450981.2500 - reconstruction_loss: 450981.2500 - kl_loss: 4.6790e-06\n",
            "Epoch 114/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 380323.3438 - reconstruction_loss: 380323.3438 - kl_loss: 4.5598e-06\n",
            "Epoch 115/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 420522.6250 - reconstruction_loss: 420522.6250 - kl_loss: 4.4703e-06\n",
            "Epoch 116/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 339311.5625 - reconstruction_loss: 339311.5625 - kl_loss: 4.2915e-06\n",
            "Epoch 117/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 409560.4375 - reconstruction_loss: 409560.4375 - kl_loss: 4.2319e-06\n",
            "Epoch 118/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 390715.6250 - reconstruction_loss: 390715.6250 - kl_loss: 4.1127e-06\n",
            "Epoch 119/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 445224.6562 - reconstruction_loss: 445224.6562 - kl_loss: 3.9935e-06\n",
            "Epoch 120/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 373180.2188 - reconstruction_loss: 373180.2188 - kl_loss: 3.9339e-06\n",
            "Epoch 121/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 392857.3750 - reconstruction_loss: 392857.3750 - kl_loss: 3.8147e-06\n",
            "Epoch 122/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 440602.9375 - reconstruction_loss: 440602.9375 - kl_loss: 3.7551e-06\n",
            "Epoch 123/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 457396.8125 - reconstruction_loss: 457396.8125 - kl_loss: 3.6359e-06\n",
            "Epoch 124/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 409462.4375 - reconstruction_loss: 409462.4375 - kl_loss: 3.5763e-06\n",
            "Epoch 125/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 452230.4375 - reconstruction_loss: 452230.4375 - kl_loss: 3.4571e-06\n",
            "Epoch 126/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 430511.6250 - reconstruction_loss: 430511.6250 - kl_loss: 3.3975e-06\n",
            "Epoch 127/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 402617.2500 - reconstruction_loss: 402617.2500 - kl_loss: 3.2187e-06\n",
            "Epoch 128/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 421922.3125 - reconstruction_loss: 421922.3125 - kl_loss: 3.1590e-06\n",
            "Epoch 129/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 377008.1875 - reconstruction_loss: 377008.1875 - kl_loss: 3.0994e-06\n",
            "Epoch 130/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 409618.4062 - reconstruction_loss: 409618.4062 - kl_loss: 2.9802e-06\n",
            "Epoch 131/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 469516.2500 - reconstruction_loss: 469516.2500 - kl_loss: 2.9206e-06\n",
            "Epoch 132/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 366043.6562 - reconstruction_loss: 366043.6562 - kl_loss: 2.8610e-06\n",
            "Epoch 133/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 393910.0000 - reconstruction_loss: 393910.0000 - kl_loss: 2.7716e-06\n",
            "Epoch 134/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 431364.1875 - reconstruction_loss: 431364.1875 - kl_loss: 2.7120e-06\n",
            "Epoch 135/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 399734.8750 - reconstruction_loss: 399734.8750 - kl_loss: 2.6524e-06\n",
            "Epoch 136/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 384544.6250 - reconstruction_loss: 384544.6250 - kl_loss: 2.5630e-06\n",
            "Epoch 137/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 430190.0625 - reconstruction_loss: 430190.0625 - kl_loss: 2.5034e-06\n",
            "Epoch 138/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 447919.8125 - reconstruction_loss: 447919.8125 - kl_loss: 2.4438e-06\n",
            "Epoch 139/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 392365.7500 - reconstruction_loss: 392365.7500 - kl_loss: 2.3842e-06\n",
            "Epoch 140/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 387223.5000 - reconstruction_loss: 387223.5000 - kl_loss: 2.3246e-06\n",
            "Epoch 141/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 342073.4375 - reconstruction_loss: 342073.4375 - kl_loss: 2.2650e-06\n",
            "Epoch 142/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 422054.2500 - reconstruction_loss: 422054.2500 - kl_loss: 2.2054e-06\n",
            "Epoch 143/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 419024.2812 - reconstruction_loss: 419024.2812 - kl_loss: 2.1458e-06\n",
            "Epoch 144/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 413971.9062 - reconstruction_loss: 413971.9062 - kl_loss: 2.0862e-06\n",
            "Epoch 145/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 363522.8125 - reconstruction_loss: 363522.8125 - kl_loss: 2.0266e-06\n",
            "Epoch 146/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 419327.5000 - reconstruction_loss: 419327.5000 - kl_loss: 1.9670e-06\n",
            "Epoch 147/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 450216.6875 - reconstruction_loss: 450216.6875 - kl_loss: 1.9073e-06\n",
            "Epoch 148/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 414318.0000 - reconstruction_loss: 414318.0000 - kl_loss: 1.8775e-06\n",
            "Epoch 149/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 351701.2188 - reconstruction_loss: 351701.2188 - kl_loss: 1.8179e-06\n",
            "Epoch 150/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 449763.3750 - reconstruction_loss: 449759.3125 - kl_loss: 4.0590\n",
            "Epoch 151/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 448217.6250 - reconstruction_loss: 448217.6250 - kl_loss: 1.4901e-06\n",
            "Epoch 152/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 423454.9375 - reconstruction_loss: 423454.9375 - kl_loss: 2.2054e-06\n",
            "Epoch 153/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 381627.5625 - reconstruction_loss: 381627.5625 - kl_loss: 3.5167e-06\n",
            "Epoch 154/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 383726.4062 - reconstruction_loss: 383726.4062 - kl_loss: 5.2452e-06\n",
            "Epoch 155/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 413280.4375 - reconstruction_loss: 413280.4375 - kl_loss: 7.2122e-06\n",
            "Epoch 156/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 394702.1562 - reconstruction_loss: 394702.1562 - kl_loss: 9.0599e-06\n",
            "Epoch 157/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 390819.9375 - reconstruction_loss: 390819.9375 - kl_loss: 1.0908e-05\n",
            "Epoch 158/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 430942.7188 - reconstruction_loss: 430942.7188 - kl_loss: 1.2517e-05\n",
            "Epoch 159/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 442136.9375 - reconstruction_loss: 442136.9375 - kl_loss: 1.3947e-05\n",
            "Epoch 160/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 493821.5625 - reconstruction_loss: 493821.5625 - kl_loss: 1.4961e-05\n",
            "Epoch 161/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 394589.6562 - reconstruction_loss: 394589.6562 - kl_loss: 1.5974e-05\n",
            "Epoch 162/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 427228.9375 - reconstruction_loss: 427228.9375 - kl_loss: 1.6570e-05\n",
            "Epoch 163/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 431166.0625 - reconstruction_loss: 431166.0625 - kl_loss: 1.6987e-05\n",
            "Epoch 164/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 412065.9375 - reconstruction_loss: 412065.9375 - kl_loss: 1.7166e-05\n",
            "Epoch 165/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 430596.4062 - reconstruction_loss: 430596.4062 - kl_loss: 1.7405e-05\n",
            "Epoch 166/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 407848.1250 - reconstruction_loss: 407848.1250 - kl_loss: 1.7405e-05\n",
            "Epoch 167/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 438255.6875 - reconstruction_loss: 438255.6875 - kl_loss: 1.7464e-05\n",
            "Epoch 168/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 413696.3125 - reconstruction_loss: 413696.3125 - kl_loss: 1.7345e-05\n",
            "Epoch 169/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 407706.5312 - reconstruction_loss: 407706.5312 - kl_loss: 1.7166e-05\n",
            "Epoch 170/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 346085.4062 - reconstruction_loss: 346085.4062 - kl_loss: 1.7047e-05\n",
            "Epoch 171/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 414556.7188 - reconstruction_loss: 414556.7188 - kl_loss: 1.6868e-05\n",
            "Epoch 172/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 393200.7812 - reconstruction_loss: 393200.7812 - kl_loss: 1.6689e-05\n",
            "Epoch 173/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 391040.5312 - reconstruction_loss: 391040.5312 - kl_loss: 1.6540e-05\n",
            "Epoch 174/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 368819.8125 - reconstruction_loss: 368819.8125 - kl_loss: 1.6302e-05\n",
            "Epoch 175/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 403087.2500 - reconstruction_loss: 403087.2500 - kl_loss: 1.6063e-05\n",
            "Epoch 176/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 432198.3750 - reconstruction_loss: 432198.3750 - kl_loss: 1.5765e-05\n",
            "Epoch 177/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 391461.8125 - reconstruction_loss: 391461.8125 - kl_loss: 1.5438e-05\n",
            "Epoch 178/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 382852.3438 - reconstruction_loss: 382852.3438 - kl_loss: 1.5080e-05\n",
            "Epoch 179/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 472823.4375 - reconstruction_loss: 472823.4375 - kl_loss: 1.4693e-05\n",
            "Epoch 180/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 403527.7500 - reconstruction_loss: 403527.7500 - kl_loss: 1.4275e-05\n",
            "Epoch 181/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 385530.3125 - reconstruction_loss: 385530.3125 - kl_loss: 1.3769e-05\n",
            "Epoch 182/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 335724.1875 - reconstruction_loss: 335724.1875 - kl_loss: 1.3322e-05\n",
            "Epoch 183/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 477815.3750 - reconstruction_loss: 477815.3750 - kl_loss: 1.2785e-05\n",
            "Epoch 184/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 388526.3438 - reconstruction_loss: 388526.3438 - kl_loss: 1.2219e-05\n",
            "Epoch 185/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 368140.8125 - reconstruction_loss: 368140.8125 - kl_loss: 1.1683e-05\n",
            "Epoch 186/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 407036.0625 - reconstruction_loss: 407036.0625 - kl_loss: 1.1116e-05\n",
            "Epoch 187/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 430566.6875 - reconstruction_loss: 430566.6875 - kl_loss: 1.0580e-05\n",
            "Epoch 188/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 375367.0000 - reconstruction_loss: 375367.0000 - kl_loss: 1.0043e-05\n",
            "Epoch 189/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 379536.2188 - reconstruction_loss: 379536.2188 - kl_loss: 9.5069e-06\n",
            "Epoch 190/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 404457.3438 - reconstruction_loss: 404457.3438 - kl_loss: 9.0599e-06\n",
            "Epoch 191/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 439637.0000 - reconstruction_loss: 439637.0000 - kl_loss: 8.5533e-06\n",
            "Epoch 192/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 450259.6250 - reconstruction_loss: 450259.6250 - kl_loss: 8.1062e-06\n",
            "Epoch 193/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 421862.1250 - reconstruction_loss: 421862.1250 - kl_loss: 7.6592e-06\n",
            "Epoch 194/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 396509.0000 - reconstruction_loss: 396509.0000 - kl_loss: 7.2420e-06\n",
            "Epoch 195/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 440827.6875 - reconstruction_loss: 440827.6875 - kl_loss: 6.8545e-06\n",
            "Epoch 196/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 453667.5000 - reconstruction_loss: 453667.5000 - kl_loss: 6.4969e-06\n",
            "Epoch 197/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 445160.2500 - reconstruction_loss: 445160.2500 - kl_loss: 6.1393e-06\n",
            "Epoch 198/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 450009.7500 - reconstruction_loss: 450009.7500 - kl_loss: 5.7817e-06\n",
            "Epoch 199/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 425252.7500 - reconstruction_loss: 425252.7500 - kl_loss: 5.5432e-06\n",
            "Epoch 200/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 434388.5625 - reconstruction_loss: 434388.5625 - kl_loss: 5.2452e-06\n",
            "Epoch 201/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 408752.9375 - reconstruction_loss: 408752.9375 - kl_loss: 4.9472e-06\n",
            "Epoch 202/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 403564.4062 - reconstruction_loss: 403564.4062 - kl_loss: 4.6492e-06\n",
            "Epoch 203/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 386897.3438 - reconstruction_loss: 386897.3438 - kl_loss: 4.3511e-06\n",
            "Epoch 204/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 398120.7188 - reconstruction_loss: 398120.7188 - kl_loss: 4.1127e-06\n",
            "Epoch 205/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 428438.1250 - reconstruction_loss: 428438.1250 - kl_loss: 3.8743e-06\n",
            "Epoch 206/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 391235.9375 - reconstruction_loss: 391235.9375 - kl_loss: 3.6955e-06\n",
            "Epoch 207/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 407374.5625 - reconstruction_loss: 407374.5625 - kl_loss: 3.4571e-06\n",
            "Epoch 208/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 460729.3438 - reconstruction_loss: 460729.3438 - kl_loss: 3.2783e-06\n",
            "Epoch 209/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 406063.6875 - reconstruction_loss: 406063.6875 - kl_loss: 3.0398e-06\n",
            "Epoch 210/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 431786.4062 - reconstruction_loss: 431786.4062 - kl_loss: 2.9206e-06\n",
            "Epoch 211/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 428852.8750 - reconstruction_loss: 428852.8750 - kl_loss: 2.7418e-06\n",
            "Epoch 212/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 398184.5625 - reconstruction_loss: 398184.5625 - kl_loss: 2.6226e-06\n",
            "Epoch 213/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 438797.5625 - reconstruction_loss: 438797.5625 - kl_loss: 2.4438e-06\n",
            "Epoch 214/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 428462.3125 - reconstruction_loss: 428462.3125 - kl_loss: 2.3544e-06\n",
            "Epoch 215/226\n",
            "1/1 [==============================] - 44s 44s/step - loss: 413493.1250 - reconstruction_loss: 413493.1250 - kl_loss: 2.1756e-06\n",
            "Epoch 216/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 424630.0938 - reconstruction_loss: 424630.0938 - kl_loss: 2.0862e-06\n",
            "Epoch 217/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 394988.3438 - reconstruction_loss: 394988.3438 - kl_loss: 1.9670e-06\n",
            "Epoch 218/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 435527.0625 - reconstruction_loss: 435527.0625 - kl_loss: 1.8775e-06\n",
            "Epoch 219/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 414947.5625 - reconstruction_loss: 414947.5625 - kl_loss: 1.7881e-06\n",
            "Epoch 220/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 475764.9375 - reconstruction_loss: 475764.9375 - kl_loss: 1.6689e-06\n",
            "Epoch 221/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 360393.6875 - reconstruction_loss: 360393.6875 - kl_loss: 1.6093e-06\n",
            "Epoch 222/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 455541.0000 - reconstruction_loss: 455541.0000 - kl_loss: 1.5199e-06\n",
            "Epoch 223/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 382653.4062 - reconstruction_loss: 382653.4062 - kl_loss: 1.4305e-06\n",
            "Epoch 224/226\n",
            "1/1 [==============================] - 42s 42s/step - loss: 335466.7812 - reconstruction_loss: 335466.7812 - kl_loss: 1.3709e-06\n",
            "Epoch 225/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 406009.0938 - reconstruction_loss: 406009.0938 - kl_loss: 1.3113e-06\n",
            "Epoch 226/226\n",
            "1/1 [==============================] - 43s 43s/step - loss: 348998.5938 - reconstruction_loss: 348998.5938 - kl_loss: 1.2517e-06\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9501b95cf9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m226\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/DataAugmentedRadiography_CovidModel/VAE.tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_vae' is not defined"
          ]
        }
      ],
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(dataset, epochs=226 , steps_per_epoch=1)\n",
        "model = vae.get_vae();\n",
        "vae.save('/content/gdrive/My Drive/DataAugmentedRadiography_CovidModel/VAE.tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZTn2W0YR9WW"
      },
      "source": [
        "# Code taken from https://keras.io/examples/generative/dcgan_overriding_train_step/ and refactored  Radiography DCGANs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LpzVOLGUZHP",
        "outputId": "63592a7d-3dda-42ed-c0ab-c824ece8c136"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7232 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# load images\n",
        "image_size = (128, 128)\n",
        "img_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    radiography_dataset + '/COVID/', label_mode=None, image_size=image_size, batch_size=16,crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "dataset = img_dataset.map(lambda x: x / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqBHZFeEvnL1"
      },
      "outputs": [],
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpdanrS_Sf3K",
        "outputId": "b0b57d32-377d-48bd-80e7-6f1d31c5955c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101 4\n"
          ]
        }
      ],
      "source": [
        "generator_in_channels = latent_dim + num_classes\n",
        "discriminator_in_channels = num_channels + num_classes\n",
        "print(generator_in_channels, discriminator_in_channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi6lG4V7Siri",
        "outputId": "859b8292-9ed6-4535-974f-72a06be46ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       262272    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 32769     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 429,377\n",
            "Trainable params: 429,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 8192)              827392    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 16, 16, 256)      524544    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 1024)     8389632   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 64, 64, 1024)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 128, 128, 1024)   16778240  \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 128, 128, 1024)    0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 3)       76803     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,694,275\n",
            "Trainable params: 28,694,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(128, 128, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(1, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()\n",
        "\n",
        "     \n",
        "Model: \"discrimin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySIPqDcuSmcD"
      },
      "outputs": [],
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n",
        "    def get_gan():\n",
        "      return GAN(name='DC_GAN_RADIOLOGY_COVID')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELzgXu-lSrZg"
      },
      "outputs": [],
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        imageFolder = 0\n",
        "        for i in range(self.num_img):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save('/content/gdrive/My Drive/Data_Augmented_Radiology_COVID' + '/' + \"generated_img_%03d_%d.png\" % (epoch, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8hcEc6lNL_q",
        "outputId": "fd0ec646-7d6d-46f8-f113-69085270de6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/452\n",
            "1/1 [==============================] - 184s 184s/step - d_loss: 0.7014 - g_loss: 2.0859\n",
            "Epoch 2/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.7694 - g_loss: 0.3795\n",
            "Epoch 3/452\n",
            "1/1 [==============================] - 180s 180s/step - d_loss: 1.0199 - g_loss: 1.0482\n",
            "Epoch 4/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: 0.5918 - g_loss: 1.3964\n",
            "Epoch 5/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: 0.5781 - g_loss: 0.8322\n",
            "Epoch 6/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.4992 - g_loss: 1.1290\n",
            "Epoch 7/452\n",
            "1/1 [==============================] - 167s 167s/step - d_loss: 0.5508 - g_loss: 1.0413\n",
            "Epoch 8/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.5883 - g_loss: 0.5595\n",
            "Epoch 9/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.5470 - g_loss: 2.1485\n",
            "Epoch 10/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.5221 - g_loss: 2.4337\n",
            "Epoch 11/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.4972 - g_loss: 1.5013\n",
            "Epoch 12/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: 0.3699 - g_loss: 0.7772\n",
            "Epoch 13/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.4176 - g_loss: 1.1918\n",
            "Epoch 14/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.3611 - g_loss: 1.9066\n",
            "Epoch 15/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: 0.3477 - g_loss: 2.3379\n",
            "Epoch 16/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: 0.2548 - g_loss: 2.0674\n",
            "Epoch 17/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: 0.3126 - g_loss: 0.9016\n",
            "Epoch 18/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.3701 - g_loss: 1.9064\n",
            "Epoch 19/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: 0.2142 - g_loss: 3.4692\n",
            "Epoch 20/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: 0.0866 - g_loss: 5.2369\n",
            "Epoch 21/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: 0.3744 - g_loss: 3.6068\n",
            "Epoch 22/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.0746 - g_loss: 1.9952\n",
            "Epoch 23/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.2097 - g_loss: 1.5006\n",
            "Epoch 24/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.3483 - g_loss: 2.9704\n",
            "Epoch 25/452\n",
            "1/1 [==============================] - 167s 167s/step - d_loss: 0.3059 - g_loss: 3.6885\n",
            "Epoch 26/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.2870 - g_loss: 2.7787\n",
            "Epoch 27/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.2784 - g_loss: 2.2505\n",
            "Epoch 28/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.2921 - g_loss: 1.5439\n",
            "Epoch 29/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.2411 - g_loss: 1.4443\n",
            "Epoch 30/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.2249 - g_loss: 1.6909\n",
            "Epoch 31/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.2791 - g_loss: 1.7602\n",
            "Epoch 32/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.1932 - g_loss: 1.9265\n",
            "Epoch 33/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.4642 - g_loss: 1.6264\n",
            "Epoch 34/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.2031 - g_loss: 1.5082\n",
            "Epoch 35/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.3190 - g_loss: 1.3402\n",
            "Epoch 36/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.2368 - g_loss: 1.3544\n",
            "Epoch 37/452\n",
            "1/1 [==============================] - 164s 164s/step - d_loss: 0.2305 - g_loss: 1.5392\n",
            "Epoch 38/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.2035 - g_loss: 1.8783\n",
            "Epoch 39/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.1811 - g_loss: 2.3637\n",
            "Epoch 40/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.1098 - g_loss: 3.1210\n",
            "Epoch 41/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.4939 - g_loss: 3.0125\n",
            "Epoch 42/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.0908 - g_loss: 3.0754\n",
            "Epoch 43/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.1478 - g_loss: 3.3178\n",
            "Epoch 44/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.2144 - g_loss: 3.7206\n",
            "Epoch 45/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.2349 - g_loss: 4.2297\n",
            "Epoch 46/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.2313 - g_loss: 4.8326\n",
            "Epoch 47/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.0803 - g_loss: 5.5510\n",
            "Epoch 48/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.1405 - g_loss: 6.4010\n",
            "Epoch 49/452\n",
            "1/1 [==============================] - 169s 169s/step - d_loss: 0.0473 - g_loss: 7.4227\n",
            "Epoch 50/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.0489 - g_loss: 7.9276\n",
            "Epoch 51/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.1828 - g_loss: 7.4848\n",
            "Epoch 52/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.0383 - g_loss: 7.2945\n",
            "Epoch 53/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.0147 - g_loss: 7.2941\n",
            "Epoch 54/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.0402 - g_loss: 7.4262\n",
            "Epoch 55/452\n",
            "1/1 [==============================] - 164s 164s/step - d_loss: 0.0378 - g_loss: 7.6671\n",
            "Epoch 56/452\n",
            "1/1 [==============================] - 164s 164s/step - d_loss: 0.0432 - g_loss: 7.9162\n",
            "Epoch 57/452\n",
            "1/1 [==============================] - 164s 164s/step - d_loss: 0.0234 - g_loss: 8.3337\n",
            "Epoch 58/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.0050 - g_loss: 8.9737\n",
            "Epoch 59/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.1556 - g_loss: 9.7100\n",
            "Epoch 60/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: -0.0462 - g_loss: 10.4220\n",
            "Epoch 61/452\n",
            "1/1 [==============================] - 164s 164s/step - d_loss: -0.0382 - g_loss: 11.2743\n",
            "Epoch 62/452\n",
            "1/1 [==============================] - 164s 164s/step - d_loss: 0.0315 - g_loss: 11.2931\n",
            "Epoch 63/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: -0.0135 - g_loss: 10.9978\n",
            "Epoch 64/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: -0.0073 - g_loss: 10.8296\n",
            "Epoch 65/452\n",
            "1/1 [==============================] - 167s 167s/step - d_loss: 0.0176 - g_loss: 11.1320\n",
            "Epoch 66/452\n",
            "1/1 [==============================] - 163s 163s/step - d_loss: 0.0170 - g_loss: 12.4518\n",
            "Epoch 67/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: -0.0104 - g_loss: 15.3570\n",
            "Epoch 68/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: -0.0507 - g_loss: 21.0277\n",
            "Epoch 69/452\n",
            "1/1 [==============================] - 164s 164s/step - d_loss: 0.2033 - g_loss: 26.3274\n",
            "Epoch 70/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: -0.2167 - g_loss: 35.3952\n",
            "Epoch 71/452\n",
            "1/1 [==============================] - 167s 167s/step - d_loss: -0.1456 - g_loss: 42.2127\n",
            "Epoch 72/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: -0.1224 - g_loss: 47.7484\n",
            "Epoch 73/452\n",
            "1/1 [==============================] - 168s 168s/step - d_loss: -0.3921 - g_loss: 55.4352\n",
            "Epoch 74/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: -0.4463 - g_loss: 65.5757\n",
            "Epoch 75/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: -0.4028 - g_loss: 73.8237\n",
            "Epoch 76/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: -0.5472 - g_loss: 83.1856\n",
            "Epoch 77/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: -0.5068 - g_loss: 94.4484\n",
            "Epoch 78/452\n",
            "1/1 [==============================] - 164s 164s/step - d_loss: -0.7398 - g_loss: 108.0832\n",
            "Epoch 79/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: -0.8657 - g_loss: 124.1075\n",
            "Epoch 80/452\n",
            "1/1 [==============================] - 166s 166s/step - d_loss: 0.6492 - g_loss: 105.6514\n",
            "Epoch 81/452\n",
            "1/1 [==============================] - 164s 164s/step - d_loss: -0.5546 - g_loss: 93.5443\n",
            "Epoch 82/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.1925 - g_loss: 84.6530\n",
            "Epoch 83/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.4116 - g_loss: 79.8046\n",
            "Epoch 84/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.1697 - g_loss: 77.9297\n",
            "Epoch 85/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: 0.2734 - g_loss: 75.3588\n",
            "Epoch 86/452\n",
            "1/1 [==============================] - 165s 165s/step - d_loss: -0.0087 - g_loss: 70.2298\n",
            "Epoch 87/452\n"
          ]
        }
      ],
      "source": [
        "epochs = 452  # In practice, use ~100 epochs 452\n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(epsilon=1e-9),\n",
        "    g_optimizer=keras.optimizers.Adam(epsilon=1e-9),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs,steps_per_epoch=1, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        "\n",
        "\n",
        "model = gan.get_gan\n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_Radiology_COVIDModel/Generator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_Radiology_COVIDModel/Discriminator',save_format='tf')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmVY9ChyN7K9"
      },
      "source": [
        "# Creating DCGAN to only generate masks - test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HA-eA19N6DS"
      },
      "outputs": [],
      "source": [
        "# load images\n",
        "image_size = (128, 128)\n",
        "img_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    radiography_dataset + '/COVID/', label_mode=None, image_size=image_size, batch_size=16,crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "dataset = img_dataset.map(lambda x: x / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKa6UiK3OGzZ"
      },
      "outputs": [],
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHZmffsBOHeq",
        "outputId": "234aaf47-5370-4340-d540-d941d9c11354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 128)       262272    \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 32769     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 429,377\n",
            "Trainable params: 429,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 8192)              827392    \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 16, 16, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 32, 32, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 64, 64, 1024)     8389632   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_6 (ReLU)              (None, 64, 64, 1024)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 128, 128, 2048)   33556480  \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              (None, 128, 128, 2048)    0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 3)       153603    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,549,315\n",
            "Trainable params: 45,549,315\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(128, 128, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(2048, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "EJgeeK-GTaM4",
        "outputId": "9a468e23-a9f5-4000-bf0c-fd1baa307091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/226\n",
            "1/1 [==============================] - 332s 332s/step - d_loss: 0.6766 - g_loss: 2.2800\n",
            "Epoch 2/226\n",
            "1/1 [==============================] - 335s 335s/step - d_loss: 0.4259 - g_loss: 2.1179\n",
            "Epoch 3/226\n",
            "1/1 [==============================] - 333s 333s/step - d_loss: 0.4109 - g_loss: 0.7781\n",
            "Epoch 4/226\n",
            "1/1 [==============================] - 332s 332s/step - d_loss: 0.4756 - g_loss: 0.9290\n",
            "Epoch 5/226\n",
            "1/1 [==============================] - 328s 328s/step - d_loss: 0.4246 - g_loss: 1.2989\n",
            "Epoch 6/226\n",
            "1/1 [==============================] - 334s 334s/step - d_loss: 0.4494 - g_loss: 1.6058\n",
            "Epoch 7/226\n",
            "1/1 [==============================] - 335s 335s/step - d_loss: 0.3244 - g_loss: 1.7835\n",
            "Epoch 8/226\n",
            "1/1 [==============================] - ETA: 0s - d_loss: 0.1846 - g_loss: 2.0958"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-326a0869f464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m history = gan.fit(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGANMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                     \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m                 \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-49b602a90f0d>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mrandom_latent_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_latent_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mgenerated_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \"\"\"\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional/conv2d_transpose.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0moutput_shape_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         outputs = backend.conv2d_transpose(\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mconv2d_transpose\u001b[0;34m(x, kernel, output_shape, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   6120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdilation_rate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6122\u001b[0;31m         x = tf.compat.v1.nn.conv2d_transpose(\n\u001b[0m\u001b[1;32m   6123\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6124\u001b[0m             \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d_transpose\u001b[0;34m(value, filter, output_shape, strides, padding, data_format, name, input, filters, dilations)\u001b[0m\n\u001b[1;32m   2673\u001b[0m   with ops.name_scope(name, \"conv2d_transpose\",\n\u001b[1;32m   2674\u001b[0m                       [value, filter, output_shape]) as name:\n\u001b[0;32m-> 2675\u001b[0;31m     return conv2d_transpose_v2(\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d_transpose_v2\u001b[0;34m(input, filters, output_shape, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2759\u001b[0m     \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2761\u001b[0;31m     return gen_nn_ops.conv2d_backprop_input(\n\u001b[0m\u001b[1;32m   2762\u001b[0m         \u001b[0minput_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2763\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1414\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1417\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Conv2DBackpropInput\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 226  # In practice, use ~100 epochs 452\n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(epsilon=1e-9),\n",
        "    g_optimizer=keras.optimizers.Adam(epsilon=1e-9),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs,steps_per_epoch=1, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        "\n",
        "\n",
        "model = gan.get_gan\n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_Radiology_COVIDModel/MaskGenerator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_Radiology_COVIDModel/MaskDiscriminator',save_format='tf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ZcgZzw-cyJ",
        "outputId": "9101a8b3-30cd-46e5-b070-1be622c3a47e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2690 files belonging to 1 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "# load images\n",
        "image_size = (64, 64)\n",
        "img_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    radiography_dataset + '/Viral Pneumonia/', label_mode=None, image_size=image_size, batch_size=32,crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "dataset = img_dataset.map(lambda x: x / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAuQy-L3o_Ch"
      },
      "outputs": [],
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrJRP5N-9g7T",
        "outputId": "0234d3e0-068a-48c4-bdd2-1c9d23d25b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 8193      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 2, 2, 128)        262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 4, 4, 256)        524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 8, 8, 512)        2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 16, 16, 1024)     8389632   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_6 (ReLU)              (None, 16, 16, 1024)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 32, 32, 2048)     33556480  \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              (None, 32, 32, 2048)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 64, 64, 4096)     134221824 \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " re_lu_8 (ReLU)              (None, 64, 64, 4096)      0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 3)         110595    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 179,179,523\n",
            "Trainable params: 179,179,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(64, 64, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(1 * 1 * 128),\n",
        "        layers.Reshape((1, 1, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(2048, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(4096, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(3, kernel_size=3, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDd9AMmj9iPD"
      },
      "outputs": [],
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n",
        "    def get_gan():\n",
        "      return GAN(name='DC_GAN_RADIOGRAPHY_Pneumonia')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnY1UG_r199G"
      },
      "outputs": [],
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=100):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        imageFolder = 0\n",
        "        for i in range(self.num_img):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PNEUMONIA' + '/' + \"generated_img_%03d_%d.png\" % (epoch, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u04njmlW2CUm",
        "outputId": "2bea5d04-8436-4261-9f9a-4b52962feab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/84\n",
            "1/1 [==============================] - 558s 558s/step - d_loss: 0.7055 - g_loss: 0.8162\n",
            "Epoch 2/84\n",
            "1/1 [==============================] - 522s 522s/step - d_loss: 0.6332 - g_loss: 1.1625\n",
            "Epoch 3/84\n",
            "1/1 [==============================] - 512s 512s/step - d_loss: 0.7032 - g_loss: 0.7128\n",
            "Epoch 4/84\n",
            "1/1 [==============================] - 523s 523s/step - d_loss: 0.5234 - g_loss: 0.6818\n",
            "Epoch 5/84\n",
            "1/1 [==============================] - 514s 514s/step - d_loss: 0.4170 - g_loss: 0.6822\n",
            "Epoch 6/84\n",
            "1/1 [==============================] - 520s 520s/step - d_loss: 0.4297 - g_loss: 0.6887\n",
            "Epoch 7/84\n",
            "1/1 [==============================] - 507s 507s/step - d_loss: 0.4713 - g_loss: 0.6957\n",
            "Epoch 8/84\n",
            "1/1 [==============================] - 509s 509s/step - d_loss: 0.4761 - g_loss: 0.6992\n",
            "Epoch 9/84\n",
            "1/1 [==============================] - 511s 511s/step - d_loss: 0.4509 - g_loss: 0.7004\n",
            "Epoch 10/84\n",
            "1/1 [==============================] - 522s 522s/step - d_loss: 0.4382 - g_loss: 0.7017\n",
            "Epoch 11/84\n",
            "1/1 [==============================] - 541s 541s/step - d_loss: 0.4118 - g_loss: 0.7034\n",
            "Epoch 12/84\n",
            "1/1 [==============================] - 518s 518s/step - d_loss: 0.4005 - g_loss: 0.7055\n",
            "Epoch 13/84\n",
            "1/1 [==============================] - 520s 520s/step - d_loss: 0.4138 - g_loss: 0.7080\n",
            "Epoch 14/84\n",
            "1/1 [==============================] - 500s 500s/step - d_loss: 0.4193 - g_loss: 0.7109\n",
            "Epoch 15/84\n",
            "1/1 [==============================] - 501s 501s/step - d_loss: 0.4130 - g_loss: 0.7144\n",
            "Epoch 16/84\n",
            "1/1 [==============================] - 499s 499s/step - d_loss: 0.4155 - g_loss: 0.7188\n",
            "Epoch 17/84\n",
            "1/1 [==============================] - 502s 502s/step - d_loss: 0.3935 - g_loss: 0.7242\n",
            "Epoch 18/84\n",
            "1/1 [==============================] - 514s 514s/step - d_loss: 0.3960 - g_loss: 0.7310\n",
            "Epoch 19/84\n",
            "1/1 [==============================] - 516s 516s/step - d_loss: 0.3952 - g_loss: 0.7400\n",
            "Epoch 20/84\n",
            "1/1 [==============================] - 521s 521s/step - d_loss: 0.3928 - g_loss: 0.7518\n",
            "Epoch 21/84\n",
            "1/1 [==============================] - 504s 504s/step - d_loss: 0.3886 - g_loss: 0.7673\n",
            "Epoch 22/84\n",
            "1/1 [==============================] - 494s 494s/step - d_loss: 0.3800 - g_loss: 0.7878\n",
            "Epoch 23/84\n",
            "1/1 [==============================] - 497s 497s/step - d_loss: 0.3722 - g_loss: 0.8148\n",
            "Epoch 24/84\n",
            "1/1 [==============================] - 505s 505s/step - d_loss: 0.3564 - g_loss: 0.8506\n",
            "Epoch 25/84\n",
            "1/1 [==============================] - 508s 508s/step - d_loss: 0.3340 - g_loss: 0.8988\n",
            "Epoch 26/84\n",
            "1/1 [==============================] - 499s 499s/step - d_loss: 0.3171 - g_loss: 0.9630\n",
            "Epoch 27/84\n",
            "1/1 [==============================] - 512s 512s/step - d_loss: 0.3000 - g_loss: 1.0497\n",
            "Epoch 28/84\n",
            "1/1 [==============================] - 507s 507s/step - d_loss: 0.2807 - g_loss: 1.1657\n",
            "Epoch 29/84\n",
            "1/1 [==============================] - 508s 508s/step - d_loss: 0.2469 - g_loss: 1.3248\n",
            "Epoch 30/84\n",
            "1/1 [==============================] - 510s 510s/step - d_loss: 0.2140 - g_loss: 1.5394\n",
            "Epoch 31/84\n"
          ]
        }
      ],
      "source": [
        "epochs = 84  # In practice, use ~100 epochs\n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(epsilon=1e-8),\n",
        "    g_optimizer=keras.optimizers.Adam(epsilon=1e-8),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs,steps_per_epoch=1, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        " \n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PNEUMONIAModel/Generator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PNEUMONIAModel/Discriminator',save_format='tf')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI2ALLkCR2vt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}