{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i-KAqwHSkFqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbae82f2-bf94-47d3-8f6e-cda2deb8007b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            " COVID\t\t\t      Normal.metadata.xlsx\n",
            " COVID.metadata.xlsx\t      README.md.txt\n",
            " Lung_Opacity.metadata.xlsx  'Viral Pneumonia'\n",
            " Normal\t\t\t     'Viral Pneumonia.metadata.xlsx'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (23.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls \"/content/gdrive/My Drive/COVID-19_Radiography_Dataset\"\n",
        "!pip install pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u4JUZUnIjArU"
      },
      "outputs": [],
      "source": [
        "import keras \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "from IPython import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from enum import Enum\n",
        "from glob import glob\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import gdown\n",
        "from zipfile import ZipFile\n",
        "# for reproducibility - ref https://machinelearningmastery.com/reproducible-results-neural-networks-keras/ and https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed\n",
        "np.random.seed(9)\n",
        "tf.keras.utils.set_random_seed(10)\n",
        "\n",
        "# loading data from gdrive\n",
        "chest_xray_dataset = os.path.abspath(\"/content/gdrive/My Drive/COVID 19 CHEST XRAY/images\")\n",
        "chest_xray_dataset_annotations = os.path.abspath(\"/content/gdrive/My Drive/COVID 19 CHEST XRAY/metadata.csv\")\n",
        "radiography_dataset = os.path.abspath(\"/content/gdrive/My Drive/COVID-19_Radiography_Dataset/\")\n",
        "xray_covid19_dataset = os.path.abspath(\"/content/gdrive/My Drive/xray_dataset_covid19/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Gy_GXINDq0-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9426e272-f40a-4eda-a8cf-2aeb08577fd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}\n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#@markdown #**Anti-Disconnect for Google Colab**\n",
        "#@markdown ## Run this to stop it from disconnecting automatically \n",
        "#@markdown  **(It will anyhow disconnect after 6 - 12 hrs for using the free version of Colab.)**\n",
        "#@markdown  *(Colab Pro users will get about 24 hrs usage time)*\n",
        "#@markdown ---\n",
        "# taken from https://colab.research.google.com/github/justinjohn0306/VQGAN-CLIP/blob/main/VQGAN%2BCLIP_%28z%2Bquantize_method_with_augmentations%2C_user_friendly_interface%29.ipynb#scrollTo=XHyPd4oxVp_l stops colab disconnecting\n",
        "import IPython\n",
        "js_code = '''\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''\n",
        "IPython.display.Javascript(js_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "qSpMb9aHjQT4",
        "outputId": "e0824c18-c4a0-4df1-ecfa-3b0be36eb035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7232 files belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# load images\n",
        "image_size = (128, 128)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "dataset = keras.utils.image_dataset_from_directory(\n",
        "    radiography_dataset + '/COVID', label_mode=None, image_size=image_size, batch_size=32\n",
        ")\n",
        "for images in dataset.take(4):\n",
        "  for i in range(1):\n",
        "      ax = plt.subplot(2, 2, i + 1)\n",
        "      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "      plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TndIIeA7R5IK"
      },
      "source": [
        "# Code taken from ref https://keras.io/examples/generative/vae/ and refactored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NKKXZDF3P5o"
      },
      "outputs": [],
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRqfi82oD8q3",
        "outputId": "3994e9f5-9092-4f2e-d529-240347dc8e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 64, 32)   896         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 64)   18496       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 128)  73856       ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 32768)        0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 16)           524304      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 1)            17          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 1)            17          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 1)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 617,586\n",
            "Trainable params: 617,586\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 1\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(128, 128, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2D(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl-lUO8PnvxI",
        "outputId": "188b39cc-ce6c-4fd9-ff5e-d99f865d298c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                128       \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 1, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 2, 2, 32)         18464     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 4, 4, 64)         18496     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 8, 8, 128)        73856     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 16, 16, 256)      295168    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 32, 32, 512)      1180160   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 64, 64, 728)      3355352   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 128, 128, 1024)   6710272   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 128, 128, 1)      9217      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,661,113\n",
            "Trainable params: 11,661,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(1 * 1 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((1, 1, 64))(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(512, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(728, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(1024, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "\n",
        "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crjHnHiplTek"
      },
      "outputs": [],
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.mae(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "    def get_vae():\n",
        "      return VAE(name='VAERadiographyCOVID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "15ivoe-vnzsC",
        "outputId": "d9afe6a5-fc7a-4033-a46d-98f0bff128fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 24/226 [==>...........................] - ETA: 2:00 - loss: nan - reconstruction_loss: nan - kl_loss: nan"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2ff6def429d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/DataAugmentedRadiography_Models/COVIDVAE.tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(dataset, epochs=10)\n",
        "vae.save('/content/gdrive/My Drive/DataAugmentedRadiography_Models/COVIDVAE.tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZTn2W0YR9WW"
      },
      "source": [
        "# Code taken from https://keras.io/examples/generative/dcgan_overriding_train_step/ and refactored  Radiography DCGANs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpzVOLGUZHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8821e3-b55d-46d2-f834-a36ed6893da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7232 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# load images\n",
        "image_size = (128, 128)\n",
        "img_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    radiography_dataset + '/COVID/', label_mode=None, image_size=image_size, batch_size=8,crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "dataset = img_dataset.map(lambda x: x / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqBHZFeEvnL1"
      },
      "outputs": [],
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wqHu15dEBHU5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpdanrS_Sf3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee8d596-ee19-441f-c15f-e31c936b04f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "257 4\n"
          ]
        }
      ],
      "source": [
        "generator_in_channels = latent_dim + num_classes\n",
        "discriminator_in_channels = num_channels + num_classes\n",
        "print(generator_in_channels, discriminator_in_channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi6lG4V7Siri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194022b0-eb45-4a24-a5c5-244596a76630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 128)       262272    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 32769     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 429,377\n",
            "Trainable params: 429,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 8192)              2105344   \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_8 (Conv2DT  (None, 16, 16, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_9 (Conv2DT  (None, 32, 32, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_10 (Conv2D  (None, 64, 64, 1024)     8389632   \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 1024)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_11 (Conv2D  (None, 128, 128, 2048)   33556480  \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 128, 128, 2048)    0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 128, 128, 3)       98307     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,771,971\n",
            "Trainable params: 46,771,971\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(128, 128, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(2048, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=4, padding=\"same\", activation=\"tanh\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySIPqDcuSmcD"
      },
      "outputs": [],
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n",
        "    def get_gan():\n",
        "      return GAN(name='DC_GAN_Radiography_COVID')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELzgXu-lSrZg"
      },
      "outputs": [],
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=latent_dim):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        imageFolder = 0\n",
        "        for i in range(self.num_img):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save('/content/gdrive/My Drive/Data_Augmented_Radiography_COVID' + '/' + \"generated_img_%03d_%d.png\" % (epoch, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8hcEc6lNL_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af920786-0db9-4732-8033-c366cf3db902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "904/904 [==============================] - 159s 167ms/step - d_loss: 0.6064 - g_loss: 0.9463\n",
            "Epoch 2/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5557 - g_loss: 1.2204\n",
            "Epoch 3/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6494 - g_loss: 1.0036\n",
            "Epoch 4/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6594 - g_loss: 0.9330\n",
            "Epoch 5/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6456 - g_loss: 0.9435\n",
            "Epoch 6/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5360 - g_loss: 1.2437\n",
            "Epoch 7/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5665 - g_loss: 1.1024\n",
            "Epoch 8/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6155 - g_loss: 1.0067\n",
            "Epoch 9/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6102 - g_loss: 1.0518\n",
            "Epoch 10/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6151 - g_loss: 1.0928\n",
            "Epoch 11/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6170 - g_loss: 1.0831\n",
            "Epoch 12/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6209 - g_loss: 1.0972\n",
            "Epoch 13/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6248 - g_loss: 1.0954\n",
            "Epoch 14/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6145 - g_loss: 1.1159\n",
            "Epoch 15/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6283 - g_loss: 1.1001\n",
            "Epoch 16/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6261 - g_loss: 1.0901\n",
            "Epoch 17/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5572 - g_loss: 1.3135\n",
            "Epoch 18/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5388 - g_loss: 1.2877\n",
            "Epoch 19/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5302 - g_loss: 1.2640\n",
            "Epoch 20/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5288 - g_loss: 1.2159\n",
            "Epoch 21/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5968 - g_loss: 1.0325\n",
            "Epoch 22/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6168 - g_loss: 1.0467\n",
            "Epoch 23/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6196 - g_loss: 1.0330\n",
            "Epoch 24/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6185 - g_loss: 1.0536\n",
            "Epoch 25/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6281 - g_loss: 1.0436\n",
            "Epoch 26/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6249 - g_loss: 1.0654\n",
            "Epoch 27/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6206 - g_loss: 1.0686\n",
            "Epoch 28/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6265 - g_loss: 1.0795\n",
            "Epoch 29/100\n",
            "904/904 [==============================] - 150s 166ms/step - d_loss: 0.6432 - g_loss: 1.0912\n",
            "Epoch 30/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6300 - g_loss: 1.0699\n",
            "Epoch 31/100\n",
            "904/904 [==============================] - 150s 166ms/step - d_loss: 0.6239 - g_loss: 1.0913\n",
            "Epoch 32/100\n",
            "904/904 [==============================] - 151s 166ms/step - d_loss: 0.6346 - g_loss: 1.0992\n",
            "Epoch 33/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6294 - g_loss: 1.0768\n",
            "Epoch 34/100\n",
            "904/904 [==============================] - 150s 166ms/step - d_loss: 0.6339 - g_loss: 1.0794\n",
            "Epoch 35/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6361 - g_loss: 1.0798\n",
            "Epoch 36/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6289 - g_loss: 1.0702\n",
            "Epoch 37/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6366 - g_loss: 1.0684\n",
            "Epoch 38/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6419 - g_loss: 1.0631\n",
            "Epoch 39/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6452 - g_loss: 1.0674\n",
            "Epoch 40/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6436 - g_loss: 1.0707\n",
            "Epoch 41/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6400 - g_loss: 1.0583\n",
            "Epoch 42/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6523 - g_loss: 1.0560\n",
            "Epoch 43/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6416 - g_loss: 1.0792\n",
            "Epoch 44/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6539 - g_loss: 1.0502\n",
            "Epoch 45/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6572 - g_loss: 1.0442\n",
            "Epoch 46/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6463 - g_loss: 1.0410\n",
            "Epoch 47/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6551 - g_loss: 1.0416\n",
            "Epoch 48/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6516 - g_loss: 1.0379\n",
            "Epoch 49/100\n",
            "904/904 [==============================] - 151s 166ms/step - d_loss: 0.6605 - g_loss: 1.0489\n",
            "Epoch 50/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6464 - g_loss: 1.0350\n",
            "Epoch 51/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5730 - g_loss: 1.2645\n",
            "Epoch 52/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5409 - g_loss: 1.3408\n",
            "Epoch 53/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5411 - g_loss: 1.3324\n",
            "Epoch 54/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5508 - g_loss: 1.3195\n",
            "Epoch 55/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5401 - g_loss: 1.3019\n",
            "Epoch 56/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5393 - g_loss: 1.2864\n",
            "Epoch 57/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5537 - g_loss: 1.2162\n",
            "Epoch 58/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6329 - g_loss: 0.9999\n",
            "Epoch 59/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6379 - g_loss: 0.9814\n",
            "Epoch 60/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6410 - g_loss: 0.9970\n",
            "Epoch 61/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6513 - g_loss: 0.9931\n",
            "Epoch 62/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6442 - g_loss: 1.0014\n",
            "Epoch 63/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6606 - g_loss: 1.0050\n",
            "Epoch 64/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6529 - g_loss: 1.0037\n",
            "Epoch 65/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6473 - g_loss: 0.9992\n",
            "Epoch 66/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6484 - g_loss: 1.0193\n",
            "Epoch 67/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6445 - g_loss: 1.0060\n",
            "Epoch 68/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6551 - g_loss: 1.0302\n",
            "Epoch 69/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6450 - g_loss: 1.0447\n",
            "Epoch 70/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6518 - g_loss: 1.0143\n",
            "Epoch 71/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6506 - g_loss: 1.0322\n",
            "Epoch 72/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6550 - g_loss: 1.0219\n",
            "Epoch 73/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6541 - g_loss: 1.0224\n",
            "Epoch 74/100\n",
            "904/904 [==============================] - 161s 178ms/step - d_loss: 0.6538 - g_loss: 1.0374\n",
            "Epoch 75/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6535 - g_loss: 1.0426\n",
            "Epoch 76/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6452 - g_loss: 1.0423\n",
            "Epoch 77/100\n",
            "904/904 [==============================] - 152s 168ms/step - d_loss: 0.6580 - g_loss: 1.0421\n",
            "Epoch 78/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6580 - g_loss: 1.0361\n",
            "Epoch 79/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6530 - g_loss: 1.0224\n",
            "Epoch 80/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6521 - g_loss: 1.0274\n",
            "Epoch 81/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6527 - g_loss: 1.0256\n",
            "Epoch 82/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6577 - g_loss: 1.0270\n",
            "Epoch 83/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6502 - g_loss: 1.0410\n",
            "Epoch 84/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6091 - g_loss: 1.2176\n",
            "Epoch 85/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5589 - g_loss: 1.3668\n",
            "Epoch 86/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5645 - g_loss: 1.3729\n",
            "Epoch 87/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5608 - g_loss: 1.3688\n",
            "Epoch 88/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5554 - g_loss: 1.3392\n",
            "Epoch 89/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5465 - g_loss: 1.3242\n",
            "Epoch 90/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.5440 - g_loss: 1.3170\n",
            "Epoch 91/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6179 - g_loss: 1.0540\n",
            "Epoch 92/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6512 - g_loss: 0.9952\n",
            "Epoch 93/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6591 - g_loss: 0.9881\n",
            "Epoch 94/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6627 - g_loss: 0.9943\n",
            "Epoch 95/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6583 - g_loss: 0.9829\n",
            "Epoch 96/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6593 - g_loss: 0.9994\n",
            "Epoch 97/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6552 - g_loss: 0.9984\n",
            "Epoch 98/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6501 - g_loss: 1.0105\n",
            "Epoch 99/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6552 - g_loss: 1.0067\n",
            "Epoch 100/100\n",
            "904/904 [==============================] - 151s 167ms/step - d_loss: 0.6528 - g_loss: 1.0144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "epochs = 100  # In practice, use ~100 epochs 452\n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.0001,momentum=0.001),\n",
        "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.0001,momentum=0.001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        "\n",
        "\n",
        "model = gan.get_gan\n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/Generator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/Discriminator',save_format='tf')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmVY9ChyN7K9"
      },
      "source": [
        "# Creating DCGAN to only generate masks - test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HA-eA19N6DS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adab5160-fb02-438e-8a7c-ffe1f3647204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3616 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# load images\n",
        "image_size = (128, 128)\n",
        "img_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    radiography_dataset + '/COVID/masks', label_mode=None, image_size=image_size, batch_size=8,crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "dataset = img_dataset.map(lambda x: x / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKa6UiK3OGzZ"
      },
      "outputs": [],
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHZmffsBOHeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731f67a0-fbf2-4b98-a4c1-e0babf091230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 64, 64, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_13 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 128)       262272    \n",
            "                                                                 \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 32769     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 429,377\n",
            "Trainable params: 429,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 32768)             3309568   \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 32, 32, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_15 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_16 (LeakyReLU)  (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_8 (Conv2DT  (None, 128, 128, 1024)   8389632   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_17 (LeakyReLU)  (None, 128, 128, 1024)    0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 128, 128, 3)       49155     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,370,563\n",
            "Trainable params: 14,370,563\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(128, 128, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(16 * 16 * 128),\n",
        "        layers.Reshape((16, 16, 128)),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=4, padding=\"same\", activation=\"tanh\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=latent_dim):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        imageFolder = 0\n",
        "        for i in range(self.num_img):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDMasks' + '/' + \"generated_img_%03d_%d.png\" % (epoch, i))"
      ],
      "metadata": {
        "id": "SkwotRSwyKUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJgeeK-GTaM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e61e70-a93e-4c02-9200-0e9e740e780b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "452/452 [==============================] - 65s 133ms/step - d_loss: 0.3989 - g_loss: 0.7806\n",
            "Epoch 2/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.0890 - g_loss: 2.9036\n",
            "Epoch 3/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.0452 - g_loss: 4.8231\n",
            "Epoch 4/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.4764 - g_loss: 1.9447\n",
            "Epoch 5/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.4935 - g_loss: 1.6120\n",
            "Epoch 6/100\n",
            "452/452 [==============================] - 31s 68ms/step - d_loss: 0.6130 - g_loss: 1.0814\n",
            "Epoch 7/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.6443 - g_loss: 0.9328\n",
            "Epoch 8/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.6287 - g_loss: 0.9099\n",
            "Epoch 9/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.6179 - g_loss: 0.9132\n",
            "Epoch 10/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.6208 - g_loss: 0.9142\n",
            "Epoch 11/100\n",
            "452/452 [==============================] - 31s 68ms/step - d_loss: 0.6199 - g_loss: 0.9085\n",
            "Epoch 12/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.6049 - g_loss: 0.9245\n",
            "Epoch 13/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.6032 - g_loss: 0.9269\n",
            "Epoch 14/100\n",
            "452/452 [==============================] - 32s 71ms/step - d_loss: 0.5843 - g_loss: 0.9510\n",
            "Epoch 15/100\n",
            "452/452 [==============================] - 31s 69ms/step - d_loss: 0.5777 - g_loss: 0.9605\n",
            "Epoch 16/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5826 - g_loss: 0.9425\n",
            "Epoch 17/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5865 - g_loss: 0.9427\n",
            "Epoch 18/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5878 - g_loss: 0.9398\n",
            "Epoch 19/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5976 - g_loss: 0.9287\n",
            "Epoch 20/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5989 - g_loss: 0.9196\n",
            "Epoch 21/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6038 - g_loss: 0.9140\n",
            "Epoch 22/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6050 - g_loss: 0.9054\n",
            "Epoch 23/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6042 - g_loss: 0.9081\n",
            "Epoch 24/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6051 - g_loss: 0.9039\n",
            "Epoch 25/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.6049 - g_loss: 0.8999\n",
            "Epoch 26/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6058 - g_loss: 0.9049\n",
            "Epoch 27/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6029 - g_loss: 0.9091\n",
            "Epoch 28/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6022 - g_loss: 0.9092\n",
            "Epoch 29/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6002 - g_loss: 0.9108\n",
            "Epoch 30/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6052 - g_loss: 0.9184\n",
            "Epoch 31/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5990 - g_loss: 0.9116\n",
            "Epoch 32/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5992 - g_loss: 0.9196\n",
            "Epoch 33/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5993 - g_loss: 0.9220\n",
            "Epoch 34/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5981 - g_loss: 0.9286\n",
            "Epoch 35/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5965 - g_loss: 0.9307\n",
            "Epoch 36/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5976 - g_loss: 0.9277\n",
            "Epoch 37/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5953 - g_loss: 0.9268\n",
            "Epoch 38/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5932 - g_loss: 0.9339\n",
            "Epoch 39/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5923 - g_loss: 0.9396\n",
            "Epoch 40/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5942 - g_loss: 0.9302\n",
            "Epoch 41/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5928 - g_loss: 0.9409\n",
            "Epoch 42/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5908 - g_loss: 0.9400\n",
            "Epoch 43/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5901 - g_loss: 0.9362\n",
            "Epoch 44/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5908 - g_loss: 0.9424\n",
            "Epoch 45/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5906 - g_loss: 0.9366\n",
            "Epoch 46/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5882 - g_loss: 0.9420\n",
            "Epoch 47/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5918 - g_loss: 0.9401\n",
            "Epoch 48/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5865 - g_loss: 0.9536\n",
            "Epoch 49/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5858 - g_loss: 0.9557\n",
            "Epoch 50/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5874 - g_loss: 0.9497\n",
            "Epoch 51/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5888 - g_loss: 0.9552\n",
            "Epoch 52/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5859 - g_loss: 0.9594\n",
            "Epoch 53/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5850 - g_loss: 0.9527\n",
            "Epoch 54/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5848 - g_loss: 0.9544\n",
            "Epoch 55/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5821 - g_loss: 0.9577\n",
            "Epoch 56/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5812 - g_loss: 0.9639\n",
            "Epoch 57/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5807 - g_loss: 0.9608\n",
            "Epoch 58/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5799 - g_loss: 0.9725\n",
            "Epoch 59/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5753 - g_loss: 0.9659\n",
            "Epoch 60/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5769 - g_loss: 0.9631\n",
            "Epoch 61/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5779 - g_loss: 0.9739\n",
            "Epoch 62/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5738 - g_loss: 0.9716\n",
            "Epoch 63/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5772 - g_loss: 0.9744\n",
            "Epoch 64/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5772 - g_loss: 0.9779\n",
            "Epoch 65/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5752 - g_loss: 0.9766\n",
            "Epoch 66/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5751 - g_loss: 0.9711\n",
            "Epoch 67/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5733 - g_loss: 0.9781\n",
            "Epoch 68/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5745 - g_loss: 0.9744\n",
            "Epoch 69/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5727 - g_loss: 0.9856\n",
            "Epoch 70/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5704 - g_loss: 0.9800\n",
            "Epoch 71/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5695 - g_loss: 0.9816\n",
            "Epoch 72/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5708 - g_loss: 0.9929\n",
            "Epoch 73/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5712 - g_loss: 0.9891\n",
            "Epoch 74/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5697 - g_loss: 0.9860\n",
            "Epoch 75/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5659 - g_loss: 0.9926\n",
            "Epoch 76/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5675 - g_loss: 0.9868\n",
            "Epoch 77/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5658 - g_loss: 0.9958\n",
            "Epoch 78/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5682 - g_loss: 0.9915\n",
            "Epoch 79/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5652 - g_loss: 0.9906\n",
            "Epoch 80/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5663 - g_loss: 0.9947\n",
            "Epoch 81/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5690 - g_loss: 0.9911\n",
            "Epoch 82/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5626 - g_loss: 0.9903\n",
            "Epoch 83/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5616 - g_loss: 0.9962\n",
            "Epoch 84/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5597 - g_loss: 1.0040\n",
            "Epoch 85/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5597 - g_loss: 1.0026\n",
            "Epoch 86/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5632 - g_loss: 0.9994\n",
            "Epoch 87/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5593 - g_loss: 1.0026\n",
            "Epoch 88/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5592 - g_loss: 1.0021\n",
            "Epoch 89/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5584 - g_loss: 1.0081\n",
            "Epoch 90/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5585 - g_loss: 1.0048\n",
            "Epoch 91/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5588 - g_loss: 1.0030\n",
            "Epoch 92/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5567 - g_loss: 1.0067\n",
            "Epoch 93/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5533 - g_loss: 1.0084\n",
            "Epoch 94/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5554 - g_loss: 1.0067\n",
            "Epoch 95/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5581 - g_loss: 1.0124\n",
            "Epoch 96/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5548 - g_loss: 1.0117\n",
            "Epoch 97/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5520 - g_loss: 1.0089\n",
            "Epoch 98/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5529 - g_loss: 1.0089\n",
            "Epoch 99/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.5556 - g_loss: 1.0088\n",
            "Epoch 100/100\n",
            "452/452 [==============================] - 29s 64ms/step - d_loss: 0.5476 - g_loss: 1.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "epochs = 100  # In practice, use ~100  \n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001,momentum=0),\n",
        "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001,momentum=0),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        "\n",
        "\n",
        "model = gan.get_gan\n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/MaskGenerator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/MaskDiscriminator',save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COVID XRAY"
      ],
      "metadata": {
        "id": "bbl3eWo-pH0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load images\n",
        "image_size = (128, 128)\n",
        "img_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    radiography_dataset + '/COVID/images', label_mode=None, image_size=image_size, batch_size=8,crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "dataset = img_dataset.map(lambda x: x / 255.0)"
      ],
      "metadata": {
        "id": "8PIM_EyspJmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5e4157-80fa-4d53-e03e-4e98f14022d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3616 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 256"
      ],
      "metadata": {
        "id": "FoIm-eYLpNuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=latent_dim):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        imageFolder = 0\n",
        "        for i in range(self.num_img):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDXRay' + '/' + \"generated_img_%03d_%d.png\" % (epoch, i))"
      ],
      "metadata": {
        "id": "1cUTuMygyQqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100  # In practice, use ~100  \n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001,momentum=0),\n",
        "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001,momentum=0),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        "\n",
        "\n",
        "model = gan.get_gan\n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/XRayGenerator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/XRayDiscriminator',save_format='tf')\n"
      ],
      "metadata": {
        "id": "tI5fqfospPWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092c681f-3a69-4e3b-e830-e5190feb8c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "452/452 [==============================] - 62s 66ms/step - d_loss: 0.4058 - g_loss: 7.6112\n",
            "Epoch 2/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.5833 - g_loss: 6.1387\n",
            "Epoch 3/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.3678 - g_loss: 2.9397\n",
            "Epoch 4/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.2901 - g_loss: 2.4062\n",
            "Epoch 5/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.4481 - g_loss: 0.9817\n",
            "Epoch 6/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.5865 - g_loss: 1.1771\n",
            "Epoch 7/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.3404 - g_loss: 0.9325\n",
            "Epoch 8/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.3514 - g_loss: 1.0558\n",
            "Epoch 9/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.2901 - g_loss: 0.8535\n",
            "Epoch 10/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.2421 - g_loss: 0.7160\n",
            "Epoch 11/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.2362 - g_loss: 0.8477\n",
            "Epoch 12/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.2055 - g_loss: 0.8291\n",
            "Epoch 13/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.1436 - g_loss: 0.7728\n",
            "Epoch 14/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.1099 - g_loss: 0.7739\n",
            "Epoch 15/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.0723 - g_loss: 0.8101\n",
            "Epoch 16/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.0316 - g_loss: 0.8274\n",
            "Epoch 17/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 1.0000 - g_loss: 0.8133\n",
            "Epoch 18/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.9959 - g_loss: 0.7876\n",
            "Epoch 19/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.9849 - g_loss: 0.7937\n",
            "Epoch 20/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.9552 - g_loss: 0.8229\n",
            "Epoch 21/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.9364 - g_loss: 0.8336\n",
            "Epoch 22/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.9238 - g_loss: 0.7984\n",
            "Epoch 23/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.9192 - g_loss: 0.7813\n",
            "Epoch 24/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.9120 - g_loss: 0.7812\n",
            "Epoch 25/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.9032 - g_loss: 0.7710\n",
            "Epoch 26/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.8943 - g_loss: 0.7643\n",
            "Epoch 27/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.8869 - g_loss: 0.7571\n",
            "Epoch 28/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.8816 - g_loss: 0.7505\n",
            "Epoch 29/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.8742 - g_loss: 0.7520\n",
            "Epoch 30/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.8634 - g_loss: 0.7547\n",
            "Epoch 31/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.8503 - g_loss: 0.7552\n",
            "Epoch 32/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.8404 - g_loss: 0.7528\n",
            "Epoch 33/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.8310 - g_loss: 0.7543\n",
            "Epoch 34/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.8254 - g_loss: 0.7491\n",
            "Epoch 35/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.8205 - g_loss: 0.7482\n",
            "Epoch 36/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.8133 - g_loss: 0.7473\n",
            "Epoch 37/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.8067 - g_loss: 0.7449\n",
            "Epoch 38/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.8045 - g_loss: 0.7482\n",
            "Epoch 39/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.8023 - g_loss: 0.7461\n",
            "Epoch 40/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7986 - g_loss: 0.7430\n",
            "Epoch 41/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7971 - g_loss: 0.7481\n",
            "Epoch 42/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7928 - g_loss: 0.7446\n",
            "Epoch 43/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7894 - g_loss: 0.7446\n",
            "Epoch 44/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7879 - g_loss: 0.7458\n",
            "Epoch 45/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7841 - g_loss: 0.7488\n",
            "Epoch 46/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7789 - g_loss: 0.7514\n",
            "Epoch 47/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7770 - g_loss: 0.7492\n",
            "Epoch 48/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7730 - g_loss: 0.7481\n",
            "Epoch 49/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7704 - g_loss: 0.7478\n",
            "Epoch 50/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7667 - g_loss: 0.7467\n",
            "Epoch 51/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7648 - g_loss: 0.7470\n",
            "Epoch 52/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7627 - g_loss: 0.7449\n",
            "Epoch 53/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7606 - g_loss: 0.7477\n",
            "Epoch 54/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7580 - g_loss: 0.7447\n",
            "Epoch 55/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7567 - g_loss: 0.7411\n",
            "Epoch 56/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7548 - g_loss: 0.7430\n",
            "Epoch 57/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7514 - g_loss: 0.7388\n",
            "Epoch 58/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7513 - g_loss: 0.7441\n",
            "Epoch 59/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7477 - g_loss: 0.7409\n",
            "Epoch 60/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7463 - g_loss: 0.7377\n",
            "Epoch 61/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7446 - g_loss: 0.7416\n",
            "Epoch 62/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7427 - g_loss: 0.7382\n",
            "Epoch 63/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7412 - g_loss: 0.7411\n",
            "Epoch 64/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7386 - g_loss: 0.7393\n",
            "Epoch 65/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7364 - g_loss: 0.7392\n",
            "Epoch 66/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7330 - g_loss: 0.7410\n",
            "Epoch 67/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7318 - g_loss: 0.7418\n",
            "Epoch 68/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7294 - g_loss: 0.7390\n",
            "Epoch 69/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7271 - g_loss: 0.7378\n",
            "Epoch 70/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7260 - g_loss: 0.7419\n",
            "Epoch 71/100\n",
            "452/452 [==============================] - 30s 66ms/step - d_loss: 0.7237 - g_loss: 0.7406\n",
            "Epoch 72/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7215 - g_loss: 0.7398\n",
            "Epoch 73/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7202 - g_loss: 0.7423\n",
            "Epoch 74/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7176 - g_loss: 0.7406\n",
            "Epoch 75/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7156 - g_loss: 0.7444\n",
            "Epoch 76/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7134 - g_loss: 0.7437\n",
            "Epoch 77/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7124 - g_loss: 0.7475\n",
            "Epoch 78/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7105 - g_loss: 0.7475\n",
            "Epoch 79/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7089 - g_loss: 0.7479\n",
            "Epoch 80/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7073 - g_loss: 0.7450\n",
            "Epoch 81/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7062 - g_loss: 0.7504\n",
            "Epoch 82/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7049 - g_loss: 0.7492\n",
            "Epoch 83/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7042 - g_loss: 0.7504\n",
            "Epoch 84/100\n",
            "452/452 [==============================] - 30s 65ms/step - d_loss: 0.7028 - g_loss: 0.7474\n",
            "Epoch 85/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7027 - g_loss: 0.7504\n",
            "Epoch 86/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7018 - g_loss: 0.7502\n",
            "Epoch 87/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7014 - g_loss: 0.7510\n",
            "Epoch 88/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7006 - g_loss: 0.7492\n",
            "Epoch 89/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.7000 - g_loss: 0.7475\n",
            "Epoch 90/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6993 - g_loss: 0.7524\n",
            "Epoch 91/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6986 - g_loss: 0.7529\n",
            "Epoch 92/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6978 - g_loss: 0.7519\n",
            "Epoch 93/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6974 - g_loss: 0.7515\n",
            "Epoch 94/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6972 - g_loss: 0.7516\n",
            "Epoch 95/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6970 - g_loss: 0.7549\n",
            "Epoch 96/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6967 - g_loss: 0.7508\n",
            "Epoch 97/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6966 - g_loss: 0.7542\n",
            "Epoch 98/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6962 - g_loss: 0.7521\n",
            "Epoch 99/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6957 - g_loss: 0.7540\n",
            "Epoch 100/100\n",
            "452/452 [==============================] - 29s 65ms/step - d_loss: 0.6957 - g_loss: 0.7533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pneumonia Masks DCGAN\n"
      ],
      "metadata": {
        "id": "9dj52gbGph1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load images\n",
        "image_size = (128, 128)\n",
        "img_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    radiography_dataset + '/Viral Pneumonia/masks', label_mode=None, image_size=image_size, batch_size=8,crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "dataset = img_dataset.map(lambda x: x / 255.0)"
      ],
      "metadata": {
        "id": "c0mz5ap2pn7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66cf7a23-2117-432a-8e79-c0ec263a006f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1345 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 256"
      ],
      "metadata": {
        "id": "mJ6YS_WGpprz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=latent_dim):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        imageFolder = 0\n",
        "        for i in range(self.num_img):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaMask' + '/' + \"generated_img_%03d_%d.png\" % (epoch, i))"
      ],
      "metadata": {
        "id": "6K7lA5l3yVRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100  # In practice, use ~100  \n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001,momentum=0),\n",
        "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001,momentum=0),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        "\n",
        "\n",
        "model = gan.get_gan\n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaModel/MaskGenerator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaModel/MaskDiscriminator',save_format='tf')\n"
      ],
      "metadata": {
        "id": "WSaTJ9Lqpqko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da9d84e-11fb-4482-82cb-e687e0c83949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "169/169 [==============================] - 36s 110ms/step - d_loss: 0.4507 - g_loss: 0.7043\n",
            "Epoch 2/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.3796 - g_loss: 0.7542\n",
            "Epoch 3/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.2380 - g_loss: 1.2562\n",
            "Epoch 4/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.0663 - g_loss: 2.9898\n",
            "Epoch 5/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.0235 - g_loss: 4.8121\n",
            "Epoch 6/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.0064 - g_loss: 6.3581\n",
            "Epoch 7/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 4.9314e-04 - g_loss: 7.1903\n",
            "Epoch 8/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.0524 - g_loss: 5.7055\n",
            "Epoch 9/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.2352 - g_loss: 3.4842\n",
            "Epoch 10/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.3079 - g_loss: 2.7490\n",
            "Epoch 11/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.4006 - g_loss: 2.0676\n",
            "Epoch 12/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5250 - g_loss: 1.4427\n",
            "Epoch 13/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6240 - g_loss: 1.1201\n",
            "Epoch 14/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6769 - g_loss: 0.9895\n",
            "Epoch 15/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6734 - g_loss: 0.9087\n",
            "Epoch 16/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6440 - g_loss: 0.9002\n",
            "Epoch 17/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6463 - g_loss: 0.8924\n",
            "Epoch 18/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6583 - g_loss: 0.8968\n",
            "Epoch 19/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6298 - g_loss: 0.9095\n",
            "Epoch 20/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6215 - g_loss: 0.9039\n",
            "Epoch 21/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6183 - g_loss: 0.9009\n",
            "Epoch 22/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6140 - g_loss: 0.9200\n",
            "Epoch 23/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6123 - g_loss: 0.9188\n",
            "Epoch 24/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6052 - g_loss: 0.9226\n",
            "Epoch 25/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6060 - g_loss: 0.9252\n",
            "Epoch 26/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6076 - g_loss: 0.9091\n",
            "Epoch 27/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6042 - g_loss: 0.9246\n",
            "Epoch 28/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.6044 - g_loss: 0.9141\n",
            "Epoch 29/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6038 - g_loss: 0.9264\n",
            "Epoch 30/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5973 - g_loss: 0.9293\n",
            "Epoch 31/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5944 - g_loss: 0.9352\n",
            "Epoch 32/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5872 - g_loss: 0.9289\n",
            "Epoch 33/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5878 - g_loss: 0.9461\n",
            "Epoch 34/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5856 - g_loss: 0.9551\n",
            "Epoch 35/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5848 - g_loss: 0.9463\n",
            "Epoch 36/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5794 - g_loss: 0.9415\n",
            "Epoch 37/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5759 - g_loss: 0.9716\n",
            "Epoch 38/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5755 - g_loss: 0.9583\n",
            "Epoch 39/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5732 - g_loss: 0.9706\n",
            "Epoch 40/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5713 - g_loss: 0.9564\n",
            "Epoch 41/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5772 - g_loss: 0.9620\n",
            "Epoch 42/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5706 - g_loss: 0.9685\n",
            "Epoch 43/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5769 - g_loss: 0.9662\n",
            "Epoch 44/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5771 - g_loss: 0.9635\n",
            "Epoch 45/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5787 - g_loss: 0.9577\n",
            "Epoch 46/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5773 - g_loss: 0.9673\n",
            "Epoch 47/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5779 - g_loss: 0.9593\n",
            "Epoch 48/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5784 - g_loss: 0.9607\n",
            "Epoch 49/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5787 - g_loss: 0.9681\n",
            "Epoch 50/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5794 - g_loss: 0.9616\n",
            "Epoch 51/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5798 - g_loss: 0.9588\n",
            "Epoch 52/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5808 - g_loss: 0.9614\n",
            "Epoch 53/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5828 - g_loss: 0.9556\n",
            "Epoch 54/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5815 - g_loss: 0.9569\n",
            "Epoch 55/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5839 - g_loss: 0.9447\n",
            "Epoch 56/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5836 - g_loss: 0.9530\n",
            "Epoch 57/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5844 - g_loss: 0.9494\n",
            "Epoch 58/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5863 - g_loss: 0.9624\n",
            "Epoch 59/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5861 - g_loss: 0.9564\n",
            "Epoch 60/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5853 - g_loss: 0.9509\n",
            "Epoch 61/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5857 - g_loss: 0.9401\n",
            "Epoch 62/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5859 - g_loss: 0.9580\n",
            "Epoch 63/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5864 - g_loss: 0.9660\n",
            "Epoch 64/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5889 - g_loss: 0.9461\n",
            "Epoch 65/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5887 - g_loss: 0.9426\n",
            "Epoch 66/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5897 - g_loss: 0.9456\n",
            "Epoch 67/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5942 - g_loss: 0.9494\n",
            "Epoch 68/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5916 - g_loss: 0.9409\n",
            "Epoch 69/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5914 - g_loss: 0.9295\n",
            "Epoch 70/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5941 - g_loss: 0.9467\n",
            "Epoch 71/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5947 - g_loss: 0.9309\n",
            "Epoch 72/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5941 - g_loss: 0.9508\n",
            "Epoch 73/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5918 - g_loss: 0.9385\n",
            "Epoch 74/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5941 - g_loss: 0.9354\n",
            "Epoch 75/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5940 - g_loss: 0.9348\n",
            "Epoch 76/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5947 - g_loss: 0.9445\n",
            "Epoch 77/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5958 - g_loss: 0.9399\n",
            "Epoch 78/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5923 - g_loss: 0.9329\n",
            "Epoch 79/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5934 - g_loss: 0.9348\n",
            "Epoch 80/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5949 - g_loss: 0.9382\n",
            "Epoch 81/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5956 - g_loss: 0.9412\n",
            "Epoch 82/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5946 - g_loss: 0.9293\n",
            "Epoch 83/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5947 - g_loss: 0.9394\n",
            "Epoch 84/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5946 - g_loss: 0.9333\n",
            "Epoch 85/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5931 - g_loss: 0.9386\n",
            "Epoch 86/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5974 - g_loss: 0.9378\n",
            "Epoch 87/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5899 - g_loss: 0.9444\n",
            "Epoch 88/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5948 - g_loss: 0.9320\n",
            "Epoch 89/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5950 - g_loss: 0.9394\n",
            "Epoch 90/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5948 - g_loss: 0.9347\n",
            "Epoch 91/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5944 - g_loss: 0.9312\n",
            "Epoch 92/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5967 - g_loss: 0.9504\n",
            "Epoch 93/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5919 - g_loss: 0.9371\n",
            "Epoch 94/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5972 - g_loss: 0.9407\n",
            "Epoch 95/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5925 - g_loss: 0.9410\n",
            "Epoch 96/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5948 - g_loss: 0.9361\n",
            "Epoch 97/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5924 - g_loss: 0.9338\n",
            "Epoch 98/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5931 - g_loss: 0.9386\n",
            "Epoch 99/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5936 - g_loss: 0.9474\n",
            "Epoch 100/100\n",
            "169/169 [==============================] - 11s 66ms/step - d_loss: 0.5963 - g_loss: 0.9421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pneumonia Xray DCGAN"
      ],
      "metadata": {
        "id": "n6wodvEgqEyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load images\n",
        "image_size = (128, 128)\n",
        "img_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    radiography_dataset + '/Viral Pneumonia/images', label_mode=None, image_size=image_size, batch_size=8,crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "dataset = img_dataset.map(lambda x: x / 255.0)"
      ],
      "metadata": {
        "id": "W5JQrkUzqICb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb9f038-95ee-4dbd-e2a0-745ecdd62de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1345 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 256"
      ],
      "metadata": {
        "id": "ROQAG8m2qKeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=latent_dim):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        imageFolder = 0\n",
        "        for i in range(self.num_img):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaXray' + '/' + \"generated_img_%03d_%d.png\" % (epoch, i))"
      ],
      "metadata": {
        "id": "wRL4qg9JyefC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100  # In practice, use ~100  \n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001,momentum=0),\n",
        "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001,momentum=0),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        "\n",
        "\n",
        "model = gan.get_gan\n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaModel/XRayGenerator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaModel/XRayDiscriminator',save_format='tf')\n"
      ],
      "metadata": {
        "id": "7Lc5XBowqLoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b94759b-f3d8-4738-dec7-f63e429ca468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "169/169 [==============================] - 22s 65ms/step - d_loss: 0.5418 - g_loss: 0.9267\n",
            "Epoch 2/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.5987 - g_loss: 0.9223\n",
            "Epoch 3/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6816 - g_loss: 0.8505\n",
            "Epoch 4/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6908 - g_loss: 0.8370\n",
            "Epoch 5/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6945 - g_loss: 0.7632\n",
            "Epoch 6/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6771 - g_loss: 0.7861\n",
            "Epoch 7/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6854 - g_loss: 0.7740\n",
            "Epoch 8/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6839 - g_loss: 0.7728\n",
            "Epoch 9/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6880 - g_loss: 0.7610\n",
            "Epoch 10/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6837 - g_loss: 0.7623\n",
            "Epoch 11/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6848 - g_loss: 0.7721\n",
            "Epoch 12/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6908 - g_loss: 0.7629\n",
            "Epoch 13/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6913 - g_loss: 0.7635\n",
            "Epoch 14/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6920 - g_loss: 0.7578\n",
            "Epoch 15/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6964 - g_loss: 0.7564\n",
            "Epoch 16/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6970 - g_loss: 0.7499\n",
            "Epoch 17/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6972 - g_loss: 0.7489\n",
            "Epoch 18/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6978 - g_loss: 0.7525\n",
            "Epoch 19/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6990 - g_loss: 0.7494\n",
            "Epoch 20/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6993 - g_loss: 0.7493\n",
            "Epoch 21/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6973 - g_loss: 0.7468\n",
            "Epoch 22/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6960 - g_loss: 0.7583\n",
            "Epoch 23/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6973 - g_loss: 0.7520\n",
            "Epoch 24/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6964 - g_loss: 0.7485\n",
            "Epoch 25/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6963 - g_loss: 0.7534\n",
            "Epoch 26/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6968 - g_loss: 0.7493\n",
            "Epoch 27/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6968 - g_loss: 0.7554\n",
            "Epoch 28/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6975 - g_loss: 0.7527\n",
            "Epoch 29/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6966 - g_loss: 0.7510\n",
            "Epoch 30/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6969 - g_loss: 0.7485\n",
            "Epoch 31/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6969 - g_loss: 0.7541\n",
            "Epoch 32/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6974 - g_loss: 0.7533\n",
            "Epoch 33/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6976 - g_loss: 0.7496\n",
            "Epoch 34/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6966 - g_loss: 0.7566\n",
            "Epoch 35/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6968 - g_loss: 0.7456\n",
            "Epoch 36/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6963 - g_loss: 0.7534\n",
            "Epoch 37/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6952 - g_loss: 0.7522\n",
            "Epoch 38/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6951 - g_loss: 0.7532\n",
            "Epoch 39/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6966 - g_loss: 0.7551\n",
            "Epoch 40/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6952 - g_loss: 0.7508\n",
            "Epoch 41/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6959 - g_loss: 0.7519\n",
            "Epoch 42/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6958 - g_loss: 0.7541\n",
            "Epoch 43/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6954 - g_loss: 0.7536\n",
            "Epoch 44/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6946 - g_loss: 0.7557\n",
            "Epoch 45/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6945 - g_loss: 0.7552\n",
            "Epoch 46/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6947 - g_loss: 0.7537\n",
            "Epoch 47/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6940 - g_loss: 0.7544\n",
            "Epoch 48/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6941 - g_loss: 0.7528\n",
            "Epoch 49/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6949 - g_loss: 0.7575\n",
            "Epoch 50/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6948 - g_loss: 0.7536\n",
            "Epoch 51/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6943 - g_loss: 0.7543\n",
            "Epoch 52/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6943 - g_loss: 0.7534\n",
            "Epoch 53/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6949 - g_loss: 0.7560\n",
            "Epoch 54/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6937 - g_loss: 0.7543\n",
            "Epoch 55/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6939 - g_loss: 0.7554\n",
            "Epoch 56/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6939 - g_loss: 0.7553\n",
            "Epoch 57/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6934 - g_loss: 0.7558\n",
            "Epoch 58/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6936 - g_loss: 0.7498\n",
            "Epoch 59/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6939 - g_loss: 0.7571\n",
            "Epoch 60/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6934 - g_loss: 0.7572\n",
            "Epoch 61/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6936 - g_loss: 0.7561\n",
            "Epoch 62/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6933 - g_loss: 0.7576\n",
            "Epoch 63/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6936 - g_loss: 0.7571\n",
            "Epoch 64/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6926 - g_loss: 0.7486\n",
            "Epoch 65/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6927 - g_loss: 0.7553\n",
            "Epoch 66/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6934 - g_loss: 0.7569\n",
            "Epoch 67/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6925 - g_loss: 0.7549\n",
            "Epoch 68/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6928 - g_loss: 0.7563\n",
            "Epoch 69/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6924 - g_loss: 0.7542\n",
            "Epoch 70/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6923 - g_loss: 0.7590\n",
            "Epoch 71/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6920 - g_loss: 0.7547\n",
            "Epoch 72/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6919 - g_loss: 0.7579\n",
            "Epoch 73/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6923 - g_loss: 0.7557\n",
            "Epoch 74/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6917 - g_loss: 0.7523\n",
            "Epoch 75/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6919 - g_loss: 0.7547\n",
            "Epoch 76/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6919 - g_loss: 0.7535\n",
            "Epoch 77/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6918 - g_loss: 0.7536\n",
            "Epoch 78/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6922 - g_loss: 0.7590\n",
            "Epoch 79/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6922 - g_loss: 0.7541\n",
            "Epoch 80/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6916 - g_loss: 0.7547\n",
            "Epoch 81/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6916 - g_loss: 0.7561\n",
            "Epoch 82/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6914 - g_loss: 0.7576\n",
            "Epoch 83/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6919 - g_loss: 0.7558\n",
            "Epoch 84/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6912 - g_loss: 0.7569\n",
            "Epoch 85/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6915 - g_loss: 0.7542\n",
            "Epoch 86/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6910 - g_loss: 0.7581\n",
            "Epoch 87/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6917 - g_loss: 0.7535\n",
            "Epoch 88/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6911 - g_loss: 0.7552\n",
            "Epoch 89/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6913 - g_loss: 0.7553\n",
            "Epoch 90/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6915 - g_loss: 0.7585\n",
            "Epoch 91/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6910 - g_loss: 0.7562\n",
            "Epoch 92/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6902 - g_loss: 0.7568\n",
            "Epoch 93/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6911 - g_loss: 0.7575\n",
            "Epoch 94/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6908 - g_loss: 0.7565\n",
            "Epoch 95/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6907 - g_loss: 0.7553\n",
            "Epoch 96/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6911 - g_loss: 0.7568\n",
            "Epoch 97/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6900 - g_loss: 0.7596\n",
            "Epoch 98/100\n",
            "169/169 [==============================] - 11s 65ms/step - d_loss: 0.6906 - g_loss: 0.7549\n",
            "Epoch 99/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6905 - g_loss: 0.7591\n",
            "Epoch 100/100\n",
            "169/169 [==============================] - 11s 64ms/step - d_loss: 0.6901 - g_loss: 0.7534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pneumonia DCGAN\n"
      ],
      "metadata": {
        "id": "WSGqE2YR9-B0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-ZcgZzw-cyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edece6b3-6313-44a0-fe09-86e5471fa2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2690 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# load images\n",
        "image_size = (128, 128)\n",
        "img_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    radiography_dataset + '/Viral Pneumonia/', label_mode=None, image_size=image_size, batch_size=8,crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "dataset = img_dataset.map(lambda x: x / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAuQy-L3o_Ch"
      },
      "outputs": [],
      "source": [
        "num_channels = 3\n",
        "num_classes = 1\n",
        "latent_dim = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrJRP5N-9g7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2b5800-4502-4235-f6ae-17320a8a54b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 128)       262272    \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 32769     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 429,377\n",
            "Trainable params: 429,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 32768)             8421376   \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 32, 32, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 128, 128, 1024)   8389632   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 128, 128, 1024)    0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 3)       49155     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,482,371\n",
            "Trainable params: 19,482,371\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(128, 128, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.5),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(16 * 16 * 128),\n",
        "        layers.Reshape((16, 16, 128)),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=4, padding=\"same\", activation=\"tanh\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDd9AMmj9iPD"
      },
      "outputs": [],
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n",
        "    def get_gan():\n",
        "      return GAN(name='DC_GAN_RADIOGRAPHY_Pneumonia')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnY1UG_r199G"
      },
      "outputs": [],
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=100):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        imageFolder = 0\n",
        "        for i in range(self.num_img):\n",
        "            img = tf.keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PNEUMONIA' + '/' + \"generated_img_%03d_%d.png\" % (epoch, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u04njmlW2CUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc8bcf10-f391-4777-834e-46eebf204ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "337/337 [==============================] - 28s 72ms/step - d_loss: 0.5854 - g_loss: 1.0765\n",
            "Epoch 2/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.6291 - g_loss: 0.9162\n",
            "Epoch 3/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5975 - g_loss: 1.0076\n",
            "Epoch 4/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5571 - g_loss: 1.1348\n",
            "Epoch 5/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5388 - g_loss: 1.2341\n",
            "Epoch 6/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5946 - g_loss: 1.1637\n",
            "Epoch 7/100\n",
            "337/337 [==============================] - 24s 72ms/step - d_loss: 0.6296 - g_loss: 1.1074\n",
            "Epoch 8/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.6362 - g_loss: 1.0573\n",
            "Epoch 9/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.6295 - g_loss: 1.0375\n",
            "Epoch 10/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.6233 - g_loss: 1.0400\n",
            "Epoch 11/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.6223 - g_loss: 1.0643\n",
            "Epoch 12/100\n",
            "337/337 [==============================] - 24s 72ms/step - d_loss: 0.6134 - g_loss: 1.0533\n",
            "Epoch 13/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.6133 - g_loss: 1.0879\n",
            "Epoch 14/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.6116 - g_loss: 1.0876\n",
            "Epoch 15/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.6008 - g_loss: 1.1242\n",
            "Epoch 16/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5976 - g_loss: 1.1765\n",
            "Epoch 17/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5959 - g_loss: 1.1659\n",
            "Epoch 18/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5841 - g_loss: 1.2075\n",
            "Epoch 19/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5851 - g_loss: 1.2344\n",
            "Epoch 20/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5890 - g_loss: 1.2337\n",
            "Epoch 21/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5797 - g_loss: 1.2610\n",
            "Epoch 22/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5810 - g_loss: 1.2883\n",
            "Epoch 23/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5755 - g_loss: 1.3353\n",
            "Epoch 24/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5734 - g_loss: 1.3006\n",
            "Epoch 25/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5789 - g_loss: 1.3788\n",
            "Epoch 26/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5718 - g_loss: 1.3448\n",
            "Epoch 27/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5736 - g_loss: 1.3628\n",
            "Epoch 28/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5723 - g_loss: 1.3739\n",
            "Epoch 29/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5805 - g_loss: 1.3695\n",
            "Epoch 30/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5696 - g_loss: 1.3458\n",
            "Epoch 31/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5805 - g_loss: 1.3760\n",
            "Epoch 32/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5785 - g_loss: 1.3692\n",
            "Epoch 33/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5719 - g_loss: 1.3863\n",
            "Epoch 34/100\n",
            "337/337 [==============================] - 23s 70ms/step - d_loss: 0.5819 - g_loss: 1.3940\n",
            "Epoch 35/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5755 - g_loss: 1.4016\n",
            "Epoch 36/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5616 - g_loss: 1.5045\n",
            "Epoch 37/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5499 - g_loss: 1.4563\n",
            "Epoch 38/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5639 - g_loss: 1.3302\n",
            "Epoch 39/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5585 - g_loss: 1.3300\n",
            "Epoch 40/100\n",
            "337/337 [==============================] - 25s 74ms/step - d_loss: 0.5634 - g_loss: 1.3481\n",
            "Epoch 41/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5469 - g_loss: 1.3026\n",
            "Epoch 42/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5424 - g_loss: 1.2706\n",
            "Epoch 43/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5374 - g_loss: 1.2596\n",
            "Epoch 44/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5271 - g_loss: 1.2488\n",
            "Epoch 45/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5329 - g_loss: 1.2416\n",
            "Epoch 46/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5371 - g_loss: 1.2694\n",
            "Epoch 47/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5222 - g_loss: 1.2343\n",
            "Epoch 48/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5185 - g_loss: 1.2348\n",
            "Epoch 49/100\n",
            "337/337 [==============================] - 23s 70ms/step - d_loss: 0.5168 - g_loss: 1.2353\n",
            "Epoch 50/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5161 - g_loss: 1.2250\n",
            "Epoch 51/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5145 - g_loss: 1.2220\n",
            "Epoch 52/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5150 - g_loss: 1.2175\n",
            "Epoch 53/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5099 - g_loss: 1.2233\n",
            "Epoch 54/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5101 - g_loss: 1.2254\n",
            "Epoch 55/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5099 - g_loss: 1.2106\n",
            "Epoch 56/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5104 - g_loss: 1.2080\n",
            "Epoch 57/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5291 - g_loss: 1.1671\n",
            "Epoch 58/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5614 - g_loss: 1.0979\n",
            "Epoch 59/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5624 - g_loss: 1.1116\n",
            "Epoch 60/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5633 - g_loss: 1.1342\n",
            "Epoch 61/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5651 - g_loss: 1.1362\n",
            "Epoch 62/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5591 - g_loss: 1.1587\n",
            "Epoch 63/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5578 - g_loss: 1.1878\n",
            "Epoch 64/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5573 - g_loss: 1.1621\n",
            "Epoch 65/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5508 - g_loss: 1.2352\n",
            "Epoch 66/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5539 - g_loss: 1.2095\n",
            "Epoch 67/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5530 - g_loss: 1.2357\n",
            "Epoch 68/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5380 - g_loss: 1.3351\n",
            "Epoch 69/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5257 - g_loss: 1.2917\n",
            "Epoch 70/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5260 - g_loss: 1.2777\n",
            "Epoch 71/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5371 - g_loss: 1.2285\n",
            "Epoch 72/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5257 - g_loss: 1.2446\n",
            "Epoch 73/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5306 - g_loss: 1.2631\n",
            "Epoch 74/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5295 - g_loss: 1.2382\n",
            "Epoch 75/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5226 - g_loss: 1.2476\n",
            "Epoch 76/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5181 - g_loss: 1.2358\n",
            "Epoch 77/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5165 - g_loss: 1.2197\n",
            "Epoch 78/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5192 - g_loss: 1.2228\n",
            "Epoch 79/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5176 - g_loss: 1.2255\n",
            "Epoch 80/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5122 - g_loss: 1.2181\n",
            "Epoch 81/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5118 - g_loss: 1.2083\n",
            "Epoch 82/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5125 - g_loss: 1.2151\n",
            "Epoch 83/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5105 - g_loss: 1.2181\n",
            "Epoch 84/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5153 - g_loss: 1.2014\n",
            "Epoch 85/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5452 - g_loss: 1.1153\n",
            "Epoch 86/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5676 - g_loss: 1.0701\n",
            "Epoch 87/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5745 - g_loss: 1.0803\n",
            "Epoch 88/100\n",
            "337/337 [==============================] - 24s 71ms/step - d_loss: 0.5700 - g_loss: 1.0876\n",
            "Epoch 89/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5649 - g_loss: 1.1111\n",
            "Epoch 90/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5638 - g_loss: 1.1326\n",
            "Epoch 91/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5713 - g_loss: 1.1733\n",
            "Epoch 92/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5592 - g_loss: 1.1631\n",
            "Epoch 93/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5575 - g_loss: 1.2163\n",
            "Epoch 94/100\n",
            "337/337 [==============================] - 23s 69ms/step - d_loss: 0.5188 - g_loss: 1.2844\n",
            "Epoch 95/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5337 - g_loss: 1.2608\n",
            "Epoch 96/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5180 - g_loss: 1.2544\n",
            "Epoch 97/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5173 - g_loss: 1.2382\n",
            "Epoch 98/100\n",
            "337/337 [==============================] - 24s 70ms/step - d_loss: 0.5135 - g_loss: 1.2444\n",
            "Epoch 99/100\n",
            "337/337 [==============================] - 22s 65ms/step - d_loss: 0.5166 - g_loss: 1.2295\n",
            "Epoch 100/100\n",
            "337/337 [==============================] - 22s 64ms/step - d_loss: 0.5138 - g_loss: 1.2470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "epochs = 100  # In practice, use ~100 epochs\n",
        "\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.0001,momentum=0.001),\n",
        "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.0001,momentum=0.001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "history = gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")\n",
        " \n",
        "# Save the model\n",
        "generator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PNEUMONIAModel/Generator',save_format='tf')\n",
        "discriminator.save('/content/gdrive/My Drive/Data_Augmented_Radiography_PNEUMONIAModel/Discriminator',save_format='tf')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading models"
      ],
      "metadata": {
        "id": "0Q9r8azxGPHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COVID Models\n"
      ],
      "metadata": {
        "id": "BTFGDKyELwQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masks"
      ],
      "metadata": {
        "id": "b_PsvTRJL2Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n",
        "    def get_gan():\n",
        "      return GAN(name='DC_GAN_RADIOGRAPHY_Pneumonia')\n"
      ],
      "metadata": {
        "id": "foQWWsq-M3mU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI2ALLkCR2vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557a8cf8-4c5d-4ba7-d000-79a022c0df2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "# 6,576 need to generate to bring up to same level as normal class\n",
        "# due to memory limitations these needed to be generated in batches of 10\n",
        "\n",
        "generator = keras.models.load_model('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/MaskGenerator/')\n",
        "discriminator = keras.models.load_model('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/MaskDiscriminator/')\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=256)\n",
        "gan.compile(\n",
        "    discriminator,\n",
        "    generator,\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "generated_batch = 0\n",
        "generator.summary\n",
        "for i in range(657):\n",
        "  random_latent_vectors = tf.random.normal(shape=(10, 100))\n",
        "  generated_images = gan.generator(random_latent_vectors)\n",
        "  generated_images *= 255\n",
        "  generated_images.numpy()\n",
        "  imageFolder = 0\n",
        "  for j in range(10):\n",
        "    img = tf.keras.preprocessing.image.array_to_img(generated_images[j])\n",
        "    img.save('/content/gdrive/My Drive/COVIDMaskAugmentedRadiographyFinal' + '/' + \"generated_img_%03d_%d.png\" % (generated_batch,j))\n",
        "  generated_batch += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### X-Ray"
      ],
      "metadata": {
        "id": "T-zUSRCTL4Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6,576 need to generate to bring up to same level as normal class\n",
        "# due to memory limitations these needed to be generated in batches of 10\n",
        "\n",
        "generator = keras.models.load_model('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/XRayGenerator/')\n",
        "discriminator = keras.models.load_model('/content/gdrive/My Drive/Data_Augmented_Radiography_COVIDModel/XRayDiscriminator/')\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=256)\n",
        "gan.compile(\n",
        "    discriminator,\n",
        "    generator,\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "generated_batch = 0\n",
        "generator.summary\n",
        "for i in range(657):\n",
        "  random_latent_vectors = tf.random.normal(shape=(10, 256))\n",
        "  generated_images = gan.generator(random_latent_vectors)\n",
        "  generated_images *= 255\n",
        "  generated_images.numpy()\n",
        "  imageFolder = 0\n",
        "  for j in range(10):\n",
        "    img = tf.keras.preprocessing.image.array_to_img(generated_images[j])\n",
        "    img.save('/content/gdrive/My Drive/COVIDXRayAugmentedRadiographyFinal' + '/' + \"generated_img_%03d_%d.png\" % (generated_batch,j))\n",
        "  generated_batch += 1"
      ],
      "metadata": {
        "id": "geacG3yOM-bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea48f59-0ea8-42d3-ec80-a1ffedb701be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viral Pneumonia Models"
      ],
      "metadata": {
        "id": "PG9kwEYNLzI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8847 need to generate to bring up to same level as normal class\n",
        "# due to memory limitations these needed to be generated in batches of 10\n",
        "\n",
        "generator = keras.models.load_model('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaModel/MaskGenerator/')\n",
        "discriminator = keras.models.load_model('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaModel/MaskDiscriminator/')\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=256)\n",
        "gan.compile(\n",
        "    discriminator,\n",
        "    generator,\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "generated_batch = 0\n",
        "generator.summary\n",
        "for i in range(884):\n",
        "  random_latent_vectors = tf.random.normal(shape=(10, 256))\n",
        "  generated_images = gan.generator(random_latent_vectors)\n",
        "  generated_images *= 255\n",
        "  generated_images.numpy()\n",
        "  imageFolder = 0\n",
        "  for j in range(10):\n",
        "    img = tf.keras.preprocessing.image.array_to_img(generated_images[j])\n",
        "    img.save('/content/gdrive/My Drive/PNEUMONIAMaskAugmentedRadiographyFinal' + '/' + \"generated_img_%03d_%d.png\" % (generated_batch,j))\n",
        "  generated_batch += 1"
      ],
      "metadata": {
        "id": "_NE9e0b3HkYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5599190d-7874-4aea-cd69-9248da7b26b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8847 need to generate to bring up to same level as normal class\n",
        "# due to memory limitations these needed to be generated in batches of 10\n",
        "\n",
        "generator = keras.models.load_model('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaModel/XRayGenerator/')\n",
        "discriminator = keras.models.load_model('/content/gdrive/My Drive/Data_Augmented_Radiography_PneumoniaModel/XRayDiscriminator/')\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=256)\n",
        "gan.compile(\n",
        "    discriminator,\n",
        "    generator,\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "generated_batch = 0\n",
        "generator.summary\n",
        "for i in range(884):\n",
        "  random_latent_vectors = tf.random.normal(shape=(10, 256))\n",
        "  generated_images = gan.generator(random_latent_vectors)\n",
        "  generated_images *= 255\n",
        "  generated_images.numpy()\n",
        "  imageFolder = 0\n",
        "  for j in range(10):\n",
        "    img = tf.keras.preprocessing.image.array_to_img(generated_images[j])\n",
        "    img.save('/content/gdrive/My Drive/PNEUMONIAXRayAugmentedRadiographyFinal' + '/' + \"generated_img_%03d_%d.png\" % (generated_batch,j))\n",
        "  generated_batch += 1"
      ],
      "metadata": {
        "id": "IXwL_zXuG49Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d81e1de-7d2b-4c7a-8383-f897a3cd6f7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "my98A0ftZdJW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}